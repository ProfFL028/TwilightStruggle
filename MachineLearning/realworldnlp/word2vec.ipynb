{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary_hash_size = 30000000\n",
    "\n",
    "\n",
    "class Vocabulary(object):\n",
    "    \"\"\"\n",
    "    store vocabulary in huffman tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, word):\n",
    "        self.counter = 0  # vocabulary disappear counter\n",
    "        self.path = list()  # path to huffman tree node\n",
    "        self.word = word  # word\n",
    "        self.huffman_code = list  # huffman code\n",
    "        self.codeLen = 0  # huffman code length\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.word) % vocabulary_hash_size\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s(%d)\" % (self.word, self.counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28128819\n",
      "28128819\n"
     ]
    }
   ],
   "source": [
    "voc = Vocabulary(\"中国\")\n",
    "print(hash(voc))\n",
    "print(hash(\"中国\") % vocabulary_hash_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "EXP_TABLE_SIZE = 1000\n",
    "MAX_EXP = 6\n",
    "EXP_TABLE = [math.exp((i / EXP_TABLE_SIZE * 2 - 1) * MAX_EXP) for i in range(1000)]\n",
    "EXP_TABLE = [x / (x + 1) for x in EXP_TABLE]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabularies = []\n",
    "vocabulary_hash = [-1 for i in range(vocabulary_hash_size)]\n",
    "vocabularies_size = 0\n",
    "\n",
    "\n",
    "def add_word_to_hash(word):\n",
    "    global vocabularies_size\n",
    "\n",
    "    word_voc = Vocabulary(word)\n",
    "    vocabularies.append(word_voc)\n",
    "    hash_idx = hash(word_voc)\n",
    "    while vocabulary_hash[hash_idx] != -1:\n",
    "        hash_idx = (hash_idx + 1) % vocabulary_hash_size\n",
    "    vocabulary_hash[hash_idx] = vocabularies_size\n",
    "    vocabularies_size = vocabularies_size + 1\n",
    "\n",
    "    return vocabularies_size\n",
    "\n",
    "\n",
    "add_word_to_hash(\"NL\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NL\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabularies))\n",
    "print(vocabularies[0].word)\n",
    "print(vocabulary_hash[hash(vocabularies[0])])\n",
    "print(vocabulary_hash[hash(\"NL\") % vocabulary_hash_size])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def search_word(word):\n",
    "    hash_idx = hash(word) % vocabulary_hash_size\n",
    "    while True:\n",
    "        if vocabulary_hash[hash_idx] == -1:\n",
    "            return -1\n",
    "        if vocabularies[vocabulary_hash[hash_idx]].word == word:\n",
    "            return vocabulary_hash[hash_idx]\n",
    "        hash_idx = (hash_idx + 1) % vocabulary_hash_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search NL: 0\n",
      "search 中国: -1\n"
     ]
    }
   ],
   "source": [
    "print(\"search %s: %d\" % (\"NL\", search_word(\"NL\")))\n",
    "print(\"search %s: %d\" % (\"中国\", search_word(\"中国\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def reduceVocabulary(min_reduce=5):\n",
    "    global vocabularies, vocabulary_hash, vocabularies_size\n",
    "    new_idx = 0\n",
    "    for (idx, v) in enumerate(vocabularies):\n",
    "        if v.counter > min_reduce:\n",
    "            vocabularies[new_idx] = v\n",
    "            new_idx += 1\n",
    "    vocabularies = vocabularies[:new_idx]\n",
    "    vocabularies_size = new_idx\n",
    "\n",
    "    vocabulary_hash = [-1 for _ in range(vocabulary_hash_size)]\n",
    "    for (idx, v) in enumerate(vocabularies):\n",
    "        hash_idx = hash(v)\n",
    "        while vocabulary_hash[hash_idx] != -1:\n",
    "            hash_idx = hash_idx + 1\n",
    "        vocabulary_hash[hash_idx] = idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "-1\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # test reduce\n",
    "add_word_to_hash(\"中国\")\n",
    "vocabularies[0].counter = 9\n",
    "add_word_to_hash(\"浙江\")\n",
    "vocabularies[2].counter = 7\n",
    "reduceVocabulary()\n",
    "print(vocabulary_hash[hash('NL') % vocabulary_hash_size])\n",
    "print(vocabulary_hash[hash('浙江') % vocabulary_hash_size])\n",
    "print(vocabulary_hash[hash('中国') % vocabulary_hash_size])\n",
    "reduceVocabulary(999999)\n",
    "add_word_to_hash(\"NL\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained words count: 10000\n",
      "trained words count: 20000\n",
      "trained words count: 30000\n",
      "trained words count: 40000\n",
      "trained words count: 50000\n",
      "trained words count: 60000\n",
      "trained words count: 70000\n",
      "trained words count: 80000\n",
      "trained words count: 90000\n",
      "trained words count: 100000\n",
      "trained words count: 110000\n",
      "trained words count: 120000\n",
      "trained words count: 130000\n",
      "trained words count: 140000\n",
      "trained words count: 150000\n",
      "trained words count: 160000\n",
      "trained words count: 170000\n"
     ]
    }
   ],
   "source": [
    "trained_words_count = 0\n",
    "reduceVocabulary(999999)\n",
    "add_word_to_hash(\"NL\")\n",
    "\n",
    "with open(file=\"./data/lines.csv\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = f.readline()\n",
    "        words = line.strip().split(\" \")\n",
    "        for new_word in words:\n",
    "            word_idx = search_word(new_word)\n",
    "            if word_idx == -1:\n",
    "                add_word_to_hash(new_word)\n",
    "                vocabularies[-1].counter = 1\n",
    "            else:\n",
    "                vocabularies[word_idx].counter += 1\n",
    "\n",
    "            if vocabularies_size >= vocabulary_hash_size * 0.7:\n",
    "                reduceVocabulary()\n",
    "            trained_words_count += 1\n",
    "            if trained_words_count % 10000 == 0:\n",
    "                print(\"trained words count: %d\" % trained_words_count)\n",
    "        vocabularies[0].counter += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained words count: 177352\n",
      "vocabularies count: 33042\n",
      "vocabularies[500]： 关怀(12)\n"
     ]
    }
   ],
   "source": [
    "print(\"trained words count: %d\" % trained_words_count)\n",
    "print(\"vocabularies count: %d\" % len(vocabularies))\n",
    "print(\"vocabularies[500]： %s\" % vocabularies[500])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "#buble sort descending vocabularies, exclude first element(NL)\n",
    "#use quicksort if not recursive maybe quicker\n",
    "def bubble(arr):\n",
    "    arr_len = len(arr)\n",
    "    while arr_len > 0:\n",
    "        for i in range(arr_len - 1):\n",
    "            if arr[i].counter < arr[i + 1].counter:\n",
    "                arr[i], arr[i + 1] = arr[i + 1], arr[i]\n",
    "        arr_len -= 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "sorted_vocabularies = bubble(vocabularies[1:])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日(1429)\n"
     ]
    }
   ],
   "source": [
    "sorted_vocabularies.insert(0, vocabularies[0])\n",
    "print(sorted_vocabularies[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# remove vocabularies that disappeared less than 5 times.\n",
    "min_reduce = 5\n",
    "vocabulary_hash = [-1 for _ in range(vocabulary_hash_size)]\n",
    "vocabularies_size = 0\n",
    "for (idx, voc) in enumerate(sorted_vocabularies):\n",
    "    if voc.counter >= min_reduce:\n",
    "        vocabulary_hash[hash(voc)] = idx\n",
    "    else:\n",
    "        vocabularies_size = idx\n",
    "        break\n",
    "sorted_vocabularies = sorted_vocabularies[:vocabularies_size]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "5720"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_vocabularies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0]\n"
     ]
    }
   ],
   "source": [
    "arr_size = len(sorted_vocabularies)\n",
    "arr = [v.counter for v in sorted_vocabularies]\n",
    "\n",
    "count_arr = arr\n",
    "count_arr.extend([1e15 for i in range(arr_size)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# log(N) algorithm for generating huffman tree in sorted array\n",
    "pos1 = arr_size - 1\n",
    "pos2 = arr_size\n",
    "min1_idx, min2_idx = 0, 0\n",
    "parent_node = [0 for i in range(arr_size * 2 + 1)]\n",
    "binary = [0 for i in range(arr_size * 2 + 1)]\n",
    "for a in range(arr_size):\n",
    "    if pos1 >= 0:\n",
    "        if count_arr[pos1] < count_arr[pos2]:\n",
    "            min1_idx = pos1\n",
    "            pos1 -= 1\n",
    "        else:\n",
    "            min1_idx = pos2\n",
    "            pos2 += 1\n",
    "    else:\n",
    "        min1_idx = pos2\n",
    "        pos2 += 1\n",
    "\n",
    "    if pos1 >= 0:\n",
    "        if count_arr[pos1] < count_arr[pos2]:\n",
    "            min2_idx = pos1\n",
    "            pos1 -= 1\n",
    "        else:\n",
    "            min2_idx = pos2\n",
    "            pos2 += 1\n",
    "    else:\n",
    "        min2_idx = pos2\n",
    "        pos2 += 1\n",
    "    count_arr[arr_size + a] = count_arr[min1_idx] + count_arr[min2_idx]\n",
    "    parent_node[min1_idx] = arr_size + a\n",
    "    parent_node[min2_idx] = arr_size + a\n",
    "    binary[min2_idx] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "count_arr[-10:]\n",
    "for a in range(arr_size):\n",
    "    b = a\n",
    "    code_len = 0\n",
    "    code = list()\n",
    "    path_point = list()\n",
    "    while True:\n",
    "        code.append(binary[b])\n",
    "        path_point.append(b)\n",
    "        code_len += 1\n",
    "        b = parent_node[b]\n",
    "        if b == (arr_size * 2 - 2):\n",
    "            break\n",
    "\n",
    "    sorted_vocabularies[a].codeLen = code_len\n",
    "    sorted_vocabularies[a].path = [0] * (code_len + 1)\n",
    "    sorted_vocabularies[a].huffman_code = [0] * code_len\n",
    "    sorted_vocabularies[a].path[0] = arr_size - 2\n",
    "    for b in range(code_len):\n",
    "        sorted_vocabularies[a].huffman_code[code_len - b - 1] = code[b]\n",
    "        sorted_vocabularies[a].path[code_len - b] = path_point[b] - arr_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "[5718, 5717, 5715, 5711, 5702, -5720]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocabularies[0].path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}