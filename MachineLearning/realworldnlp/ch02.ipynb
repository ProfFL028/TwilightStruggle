{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.set_proxy('http://localhost:58591')\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"E:/TwilightStruggle/nltk_packages/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', 'muffins', 'cost', '%', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n",
      "['你好中国']\n"
     ]
    }
   ],
   "source": [
    "s = '''Good muffins cost %3.88\\nin New York. Please buy me two of them.\\n\\nThanks.'''\n",
    "print(word_tokenize(s))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['caress',\n 'fli',\n 'die',\n 'mule',\n 'deni',\n 'die',\n 'agre',\n 'own',\n 'humbl',\n 'size',\n 'meet',\n 'state',\n 'siez',\n 'item',\n 'sensat',\n 'tradit',\n 'refer',\n 'colon',\n 'plot']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as problems in stemming, few people use stemming today.\n",
    "from nltk.stem.porter import  PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "words = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "         'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "         'meetings', 'stating', 'siezing', 'itemization',\n",
    "         'sensational', 'traditional', 'reference', 'colonizer',\n",
    "         'plotted']\n",
    "[stemmer.stem(word) for word in words]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "['caress',\n 'fly',\n 'dy',\n 'mule',\n 'denied',\n 'died',\n 'agreed',\n 'owned',\n 'humbled',\n 'sized',\n 'meeting',\n 'stating',\n 'siezing',\n 'itemization',\n 'sensational',\n 'traditional',\n 'reference',\n 'colonizer',\n 'plotted']"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "[lemmatizer.lemmatize(word) for word in words]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "outp1 = './models/zh.text.model'\n",
    "outp2 = './models/zh.text.vector'\n",
    "\n",
    "model = Word2Vec(LineSentence(\"data/lines.csv\"), vector_size=100, window=5, min_count=5, workers=4)\n",
    "model.save(outp1)\n",
    "model.save_word2vec_format(outp2, binary=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.2659047 ,  0.62786525,  0.16519907,  0.1691265 , -0.05874673,\n       -0.7166056 ,  0.13740952,  1.1208972 , -0.3692705 , -0.30231637,\n       -0.28231004, -0.7863508 , -0.11036853,  0.19632985,  0.07763553,\n       -0.36163127,  0.31782487, -0.7000358 , -0.02804839, -1.0429534 ,\n        0.21015936,  0.05467073,  0.45463905, -0.39972737, -0.09023593,\n        0.01344048, -0.20254095, -0.2172676 , -0.45210978, -0.08666575,\n        0.35714263,  0.06240401,  0.05600855, -0.40223712, -0.09305197,\n        0.42858213,  0.11075293, -0.42557725, -0.14727342, -0.5476995 ,\n        0.19067694, -0.38177466, -0.18622856,  0.17047586,  0.32935566,\n       -0.05070125, -0.43345946,  0.25370687,  0.0190862 ,  0.29520878,\n        0.17011932, -0.11735083, -0.29642555, -0.00239219, -0.38471338,\n        0.30606067,  0.41488984, -0.12533401, -0.4373165 ,  0.17562386,\n        0.0729127 ,  0.25634697, -0.06283579,  0.16241938, -0.31298965,\n        0.26197448,  0.06789688,  0.22793555, -0.5105749 ,  0.2640258 ,\n       -0.06437451,  0.2519151 ,  0.30511546, -0.32017717,  0.43789542,\n        0.14868847, -0.09359054,  0.0374501 , -0.366957  ,  0.15639246,\n       -0.3889998 , -0.17017578, -0.20498842,  0.5997037 , -0.19305295,\n        0.0047309 , -0.0490762 ,  0.3188794 ,  0.51360273,  0.24965957,\n        0.43217373,  0.24293175,  0.24139488,  0.18768366,  0.7567543 ,\n        0.46059123,  0.33290148, -0.50228673,  0.15767679,  0.32555214],\n      dtype=float32)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector(\"蔡依林\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "sentences = LineSentence(\"data/lines.csv\")\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "model.save(\"./models/doc.model\")\n",
    "model.save_word2vec_format(\"./models/doc.vector\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.00818685,  0.10775702,  0.06745839,  0.06163462, -0.05216356],\n      dtype=float32)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vec = model.infer_vector(['蔡依林', '国民党'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}