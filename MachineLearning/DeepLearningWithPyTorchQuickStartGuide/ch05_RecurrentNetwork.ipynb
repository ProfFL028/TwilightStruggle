{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batchSize = 100\n",
    "trainSet = torchvision.datasets.MNIST(root='./data', train = True, transform=transforms.ToTensor(), download=True)\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=trainSet, batch_size=batchSize, shuffle = True)\n",
    "testSet = torchvision.datasets.MNIST(root='./data', train = False, transform=transforms.ToTensor(), download=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=testSet, batch_size=batchSize, shuffle = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Model5_1(nn.Module):\n",
    "    def __init__(self, inSize=28, hiddenSize=100, numLayers=2, outSize=10):\n",
    "        self.inSize = inSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.outSize = outSize\n",
    "\n",
    "        super(Model5_1, self).__init__()\n",
    "        self.rnn = nn.RNN(inSize, hiddenSize, numLayers, batch_first=True)\n",
    "        self.fc = nn.Linear(hiddenSize, outSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.numLayers, x.size(0), self.hiddenSize)\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def accuracy(testLoader,model):\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in testLoader:\n",
    "            images, labels = data\n",
    "            outputs = model(images.view(-1, 28,28))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return(correct / total)\n",
    "\n",
    "def benchmark(trainLoader, testLoader, model, epochs=1, lr=0.01):\n",
    "    model.__init__()\n",
    "    start = time.time()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(trainLoader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images.view(-1, 28, 28))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print('Accuracy: {0:.4f}'.format(accuracy(testLoader,model)))\n",
    "    print('Training time: {0:.2f}'.format(time.time() - start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8141\n",
      "Training time: 28.29\n",
      "Accuracy: 0.7361\n",
      "Training time: 27.97\n",
      "Accuracy: 0.8321\n",
      "Training time: 28.20\n"
     ]
    }
   ],
   "source": [
    "model5_1 = Model5_1()\n",
    "model5_2 = Model5_1(inSize=28, hiddenSize=200, numLayers=2)\n",
    "model5_3 = Model5_1(inSize=28, hiddenSize=200, numLayers=3)\n",
    "\n",
    "benchmark(trainLoader,testLoader,model5_1, epochs=1, lr=0.1)\n",
    "benchmark(trainLoader,testLoader,model5_2, epochs=1, lr=0.1)\n",
    "benchmark(trainLoader,testLoader,model5_3, epochs=1, lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Model5_2(nn.Module):\n",
    "    def __init__(self, inSize=28, hiddenSize=100, numLayers=2, outSize=10):\n",
    "        self.inSize = inSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.outSize = outSize\n",
    "        super(Model5_2, self).__init__()\n",
    "        self.lstm = nn.LSTM(self.inSize, self.hiddenSize, self.numLayers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hiddenSize, self.outSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.numLayers, x.size(0), self.hiddenSize)\n",
    "        c0 = torch.zeros(self.numLayers, x.size(0), self.hiddenSize)\n",
    "        out, (hn, cn) = self.lstm(x, (h0,c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9602\n",
      "Training time: 382.95\n"
     ]
    }
   ],
   "source": [
    "model5_2 = Model5_2()\n",
    "benchmark(trainLoader, testLoader, model5_2, epochs=5, lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 3250998\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file = unidecode.unidecode(open('data/warandpeace.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nicholas,\" she replied, handing\n",
      "him a blue exercise book filled with her firm,\n",
      "bold writing.\n",
      "\n",
      "\"A diary?\" Nicholas repeated with a shade\n",
      "of irony, and he took up the book.\n",
      "\n",
      "It was in French.\n",
      "\n",
      "December 4\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10],\n",
      "        [11],\n",
      "        [12],\n",
      "        [39],\n",
      "        [40],\n",
      "        [41]])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long().unsqueeze(1)\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "\n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / chunk_len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 23s (100 5%) 2.3661]\n",
      "Lep as prute at frilled werer 6tit and puly catrofr prou the prin bed ther rres ad \"ithe I meallo frind bast laxpredr and sat's ter hasat sop the soed the wired and prely reretadef prS coxcllhe \n",
      "and unit wit nou\n",
      "ud veney of tortel fing whe cow thing to toriu\n",
      "bovker the\n",
      "pering tarl courully th, whand ing than that thasumou ing \n",
      "Miguche\n",
      "houpied whiv that thas cerati\n",
      "the san amad the domer herained her sthe wins the cong  oll wher meng fousstarance ware sat\n",
      "thus ant wat to vely doupier'it he toklig's \n",
      "\n",
      "[0m 48s (200 10%) 2.2390]\n",
      "Less sthe cothopleved the turralf the rewatiesra thith to fade wing hoe ome beuntiderst the\n",
      "curs could count so to ith tringe pulle yurss has th the ammee and\n",
      "of cyore rerent some entrot-\n",
      "wes the hitht uresterst. \"unt the mand\n",
      "the whe reed\n",
      "int sexpple a of that nat.\n",
      "\n",
      "\n",
      "\"Yhoo well of of uner tieves roul and the the them\n",
      "be.\n",
      "\n",
      "\"\"Whounale with the gecligh the th she fulk shok . The the tallle wame I to la the fimes\n",
      "of to the cont ostow and the to coulk onte of forling prom).\n",
      "\n",
      "An if stant sats ave this  \n",
      "\n",
      "[1m 11s (300 15%) 2.1348]\n",
      "Le and ous beencang fist the sked the was count the mun, her fow Buth and in the fo was ning drone when so though and The and to hespence offilrf\n",
      "ths and\n",
      "\n",
      "beren to gomen died for nad come mont and peresco fout that sfengent incencliped the mat!\" Com pered she\n",
      "mexsing and of fming of-\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "folied Liven gary dean all the and rece. the cave lestang offer, was howrs\n",
      "the counded had caled farn was duting whence at was and of he soldaice depente bochang gare cand hang expondensring and in ficer and  \n",
      "\n",
      "[1m 35s (400 20%) 2.0498]\n",
      "Led hep and of the fere arion, ardur to your talught it and sue the had growid paffury no reprereatality as a mast and are as and som Nad his a\n",
      "low, sation ho sizone, firs houss action abouded the Frion vime of the And-\n",
      "cersime and and thirs eld\n",
      "the his then wim when row with the nos to the preadiblass ancuar reite fuls a thew ross wher un. She was to and was not tep af mes turwarrels a low of\n",
      "to the lone and oun and alve ster and aboult unem, and abould and, wich fillagaring all it where arse of  \n",
      "\n",
      "[1m 59s (500 25%) 2.3078]\n",
      "Les all the from\n",
      "the\n",
      "replispior icponing for to cauld unech to this castre the givers arily more of to repally.\n",
      "\n",
      "\"erdanim mouking you the menes would beenemered indrenivs were re and morage but armors, apsterin, the from of to his in couses from\n",
      "coutonestie-\n",
      "tice. The and st who hoince Cout the strepter unot the brims.\n",
      "\n",
      "\"I ouct it?\"\n",
      "\n",
      "whounshis her:. Hoose of frorshe Evime from to uparmms mice whide wherd\n",
      "nat in\n",
      "he in beand unen consest\n",
      "call of train taking came to mite calang, al framen for been t \n",
      "\n",
      "[2m 23s (600 30%) 1.9924]\n",
      "Le with the mantion his the every who coudped to tesely,\n",
      "yosk see-\n",
      "aned\n",
      "Andink. \"Yound.\n",
      "\n",
      "\"Whorged thise and the gona-\n",
      "perew jame the mecill his his hard\n",
      "bothotherespouptiound the\n",
      "with were histanted the kess. \"Tener on fertanturned betreanternetiem. I the K-eniced, and dended to otfully him benot in stalling to new cound to pallas to seared the concer, husting to\n",
      "re the beof the laokn hince. In he bong, hid with imperanted hursturart.\n",
      "\n",
      "\"Dene him meaty, this her and musathed her's Acht haid\n",
      "and to  \n",
      "\n",
      "[2m 47s (700 35%) 1.9603]\n",
      "Le of Duzing, cite and a stoor os the bethery did Soke morficurve. The re-\n",
      "mily and the mus and a stremse the reing for onbut what he fid the Anwhow but immbel, and to Mand offull pes-\n",
      "\n",
      "\n",
      "Coptilite deolund the remess that imposanvth, inn it\n",
      "should, \"Cormens the plasis the some crited, and awalf in Gerodbon of Bristot Mathe. It he do French was tarried fied? \"He Andne? Everast he redrod beene cented.\n",
      "\"The reast and degre that\n",
      "the wolled nover From Mape it thought goodure shee to padts. I the dell te \n",
      "\n",
      "[3m 10s (800 40%) 1.8556]\n",
      "Leather and tho per-\n",
      "cammost the pepesias that or it that the fold she the conno's dranding prowining the criate complessioss dained alonavess at the candshlove, cannoted\n",
      "the pressed (of the spears asked his the creadiling are the the spoom\n",
      "alragings the mat. Anders on all pestappt\n",
      "heiw of ferand,\"\n",
      "hass be with the hand\n",
      "re!chom\" and the\n",
      "heremprom it in there fad\n",
      "shoselve who the omperriced. \"Of that me incate and frin. .. . . . . . . .. . . . . . . . . . . . .\" I which the shapt a have a from on o \n",
      "\n",
      "[3m 34s (900 45%) 1.8582]\n",
      "Le up for me as\n",
      "the miscofwer pelever oferst, a dong accues, everwipes to the\n",
      "wither she cormectionsate of the m8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "girs be feserver of seldly. In his the colle as a mustres ddraked to\n",
      "seyes excel-\n",
      "rissen and by cource, askm. If inquiressan and recelted to looked to ali-\n",
      "bless all off the remar weeblage horse incolleet there factance sull, in men all prate\n",
      "ouster Pierre now his tuirstress:\n",
      "\n",
      "\"Whell in only jove what a countessaly a grement noock and conner a semite on in thoriach re-\n",
      "lice nost \n",
      "\n",
      "[3m 57s (1000 50%) 2.0527]\n",
      "Le dea was for the araint!\" liftaned one exce, time, he,\" said the disponed of he dissing delless no undress of the towands and with retier with the reated the pricect to this fuster I'tt so mesty in this pra-\n",
      "sicante\n",
      "forting-\n",
      "orste so the ident\n",
      "and were the trat. Weed it up turning there\n",
      "camberued the sid more of the was the camode of incens it it fill\n",
      "he was away, he said the stenning he livis inquingly canding and luind of the hower could famed the ottery clair-\n",
      "ing\n",
      "of a storne sonestigher late \n",
      "\n",
      "[4m 21s (1100 55%) 1.9103]\n",
      "Le Hent she lay and the and tiry and same on her the can one how.\n",
      "\n",
      "\"Whoushar you had fors, jusha come the furtured ores aveppsion to orfure was every erempered to even to the ra-\n",
      "ter's tractine, bight is the he ordin, and him becherous,\n",
      "but the but\n",
      "the hav, anwould at Princnered not the wa\n",
      "prial tapencess, and\n",
      "to men the trowary by there surmen in\n",
      "the preligal to that him\n",
      "groused to the had in the from a soot of elspe-\n",
      "terice it pase! Napputurow offiring bagothe.\n",
      "\n",
      "\"Have, ous recleft, thime had mor \n",
      "\n",
      "[4m 44s (1200 60%) 1.7466]\n",
      "Le hore and the right about of the Russ-\n",
      "attle\n",
      "and regicess monm his\n",
      "and turined but the did her derse\n",
      "visole, by did he the of that you me she\n",
      "fat catt at the turning his the\n",
      "ratensth,\n",
      "said not the parchand the tathing hisers.\n",
      "\"And her crops\n",
      "cact and pars fire that florselith in. He was to\n",
      "sand a the herar, \"The pescersaining the ceess.\n",
      "\n",
      "\"Frechove lifts.\n",
      "\n",
      "\"Nery was pite, like and\n",
      "the sortropled that the younk and the conful-\n",
      "sidnes them strone\n",
      "and to not solder he the som the to of to yeasking ha \n",
      "\n",
      "[5m 7s (1300 65%) 1.8393]\n",
      "Lelight\n",
      "he was it you disely the up an wores\n",
      "parce ther Pierre the poble the been of\n",
      "the had with to lights in the you,\"\n",
      "goning her in\n",
      "the\n",
      "shour fection the had; away spoble smalled his fillefter and\n",
      "some anylont with paply the think mometter betialy furneing thused with the lety for was your\n",
      "if this thing\n",
      "whing inly in the race ling them\n",
      "been excect to then frically into him-\n",
      "stung in he was, sming in the The Rrass wean of the\n",
      "some had to it as Pierre\n",
      "mirstable the me morang fircies in-\n",
      "to nester \n",
      "\n",
      "[5m 30s (1400 70%) 2.0107]\n",
      "Le man seet ot when man's rought and of the\n",
      "slessar it have happedoves she mancess an iters in the greecsisispered\n",
      "the hand moth deltscoes. the hands\n",
      "prascuassuan whet ee-\n",
      "dens accow But carthand she gost the\n",
      "vely in the trom benas have been he way. . .\n",
      "\n",
      "'Ofter when cones in the cangience. One was nor acquasian betion, at Listence of her\n",
      "evew trishing as command me interes him beords from and seain Niccom had could not in? . .\n",
      "\n",
      "\"Whore there all go last of aftate to regatican, pless in the re-\n",
      "plye \n",
      "\n",
      "[5m 52s (1500 75%) 2.0077]\n",
      "Le\n",
      "at happed to mile! It\n",
      "had only a man and be\n",
      "would had he father . .. He way and\n",
      "mone fering yourne bluzal the bereming streeter a quild\n",
      "whill had thous is mand who and the plathingly innered armen a loing army. that\n",
      "hean at seemed ball for\n",
      "heavice armed and did who lownt as it seemate, the baricand who to seemen\n",
      "of the rain was the promily\n",
      "and they expellecting your with forned\n",
      "beadd Damen of himbors badly with viself poss wose\n",
      "reech, hean dabander sojilents at that the had as as looked there l \n",
      "\n",
      "[6m 14s (1600 80%) 1.7862]\n",
      "Le, and he dising the\n",
      "boother he offerspice in and asce and what the so so who teminsing by rosders he the pagant in he\n",
      "prince Viffere dears.\"\n",
      "\n",
      "The Cirf in I when call, as shill the ofted thee agone to deminse Bother, aus by bet of the her, saming beressor to undery passher, revly you some mistothing. Oll cours your had gant!\"\n",
      "mangess of them pitters and him, to you neve by on youk the ramaranse or and will devery and to to how sighture to the pricriess, and\n",
      "Pierre Mos seizing asked Pierre ancfiel \n",
      "\n",
      "[6m 37s (1700 85%) 1.9185]\n",
      "Le Mave\n",
      "and mordi6n, do dost oldirly, reathing in unders?\"\n",
      "\n",
      "\"Ask impore at to alld avide one\n",
      "mily and forgering the decting at thing the was parien his\n",
      "pempariersture and querisin of a lightly forcended re-\n",
      "man word in and the Everine who the\n",
      "arging as the with ention oud dew, and the rightly take of that shinfiling the stung morzing the\n",
      "ard could hordaring he repidared and the with and that the ready and untable\n",
      "the mall his the cammst the repared his the dreanter. What his beng arms, and infices \n",
      "\n",
      "[6m 59s (1800 90%) 1.8861]\n",
      "Le faus guzovin-\n",
      "pened a seement to before nimes the caute\n",
      "and ask him there coman of carcharading\" sindly\n",
      "had it a morek no me said and to fielul for a batter, dast\n",
      "plase mesconnothing all the preslice a\n",
      "plaity mues conticed, and done into as a custions to be\n",
      "look it sound rew, cring and as a lied all that\n",
      "teot on filloved him lown and before loured not\n",
      "on I pulied and an a gnowing the roughter it, and threatich and Pierremed who had itly\n",
      "sideroved a was all his laved face canu-\n",
      "resing, and and w \n",
      "\n",
      "[7m 22s (1900 95%) 1.8048]\n",
      "Le quaching shat he levered and of pelancled place\n",
      "of as his she ponderined adding some do to his the dest\n",
      "to like Pering the rose, a purfulsed the offere\n",
      "crow lovet now its with the caused not mentialy army bout a\n",
      "latters tear at pering every\n",
      "spearning thouted that woothing of necelteral\n",
      "offeatly some and saw Natdside her which\n",
      "I had said not eving the comber poout to peratexante oyed up to I\n",
      "\n",
      "\n",
      "\n",
      "WAR AND PCAND PEACE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\" he undelfitly, and fill of an all that\n",
      "molent or evenate of eanding of and f \n",
      "\n",
      "[7m 45s (2000 100%) 1.6258]\n",
      "Le thoice bet-\n",
      "dessand to the pressather of the seement\n",
      "was be complence and pearing sten-\n",
      "\n",
      "leffed crising been pritered for to the men to\n",
      "sharge a low hind an en-\n",
      "ting the gload after the soccher, and\n",
      "her young porment bay.\"\n",
      "\n",
      "\"The sames to ady us to her from there wask\n",
      "way morly other from thought Kutui-\n",
      "conts and such at the commanded\n",
      "\n",
      "\n",
      "PETAR\"A TR it?\" as so in stonked.\n",
      "\n",
      "\"She come seement,\" said them may a fraintly in the cross-\n",
      "entile. the compite not and treaed to perssaitey after a rep-\n",
      "salin \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#n_epochs = 2000\n",
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = [0]\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    #loss = train(*random_training_set())\n",
    "    loss = train(*random_training_set())\n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate('Le', 500), '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}