{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "              主页ID        主页名称    分类  \\\n0  155000000000000  纬来体育台官方粉丝团  电视频道   \n1     359000000000       公视粉丝团  电视频道   \n2     359000000000       公视粉丝团  电视频道   \n3     190000000000    Mobile01  网路社群   \n4     359000000000       公视粉丝团  电视频道   \n\n                                             message                    name  \\\n0                      中华队长林智胜 三分砲！！！\\n人如其名　真的「致胜」阿～                     NaN   \n1    您所选择的电视频道，将会决定您的未来~\\n遥控器的决定权，就在你手上！\\n\\n#看见更好的未来  2015公视电视募款 公视让你看见更好的未来   \n2  好演员值得更多肯定和掌声！\\n\\n吴慷仁提到大概有六、七年资历的演员，所面临的最大困境，是赚...                   公视粉丝团   \n3                              大师兄 一发炸裂！！帅啊啊啊啊啊啊啊！！！       来自 Mobile01 贴文的相片   \n4  「再不救，就来不及了！如果没有很强力的救，再三十年，你可能找不到鹿港的味道了！」\\n\\n「两...              【我们的岛】抢救鹿港   \n\n                                         description   发文类型  y  \n0                                                NaN  video  H  \n1  这是一个资讯爆炸的时代，你所选择的资讯将决定你的视野；你所选择的电视频道，将会决定你的未来 ...  video  L  \n2                                                NaN   link  L  \n3                                                NaN  photo  H  \n4  叶明兰、叶镇中 / 采访报导 「再不救，就来不及了！如果没有很强力的救，再三十年，你可能找不...   link  L  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>主页ID</th>\n      <th>主页名称</th>\n      <th>分类</th>\n      <th>message</th>\n      <th>name</th>\n      <th>description</th>\n      <th>发文类型</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>155000000000000</td>\n      <td>纬来体育台官方粉丝团</td>\n      <td>电视频道</td>\n      <td>中华队长林智胜 三分砲！！！\\n人如其名　真的「致胜」阿～</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>video</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>359000000000</td>\n      <td>公视粉丝团</td>\n      <td>电视频道</td>\n      <td>您所选择的电视频道，将会决定您的未来~\\n遥控器的决定权，就在你手上！\\n\\n#看见更好的未来</td>\n      <td>2015公视电视募款 公视让你看见更好的未来</td>\n      <td>这是一个资讯爆炸的时代，你所选择的资讯将决定你的视野；你所选择的电视频道，将会决定你的未来 ...</td>\n      <td>video</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>359000000000</td>\n      <td>公视粉丝团</td>\n      <td>电视频道</td>\n      <td>好演员值得更多肯定和掌声！\\n\\n吴慷仁提到大概有六、七年资历的演员，所面临的最大困境，是赚...</td>\n      <td>公视粉丝团</td>\n      <td>NaN</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>190000000000</td>\n      <td>Mobile01</td>\n      <td>网路社群</td>\n      <td>大师兄 一发炸裂！！帅啊啊啊啊啊啊啊！！！</td>\n      <td>来自 Mobile01 贴文的相片</td>\n      <td>NaN</td>\n      <td>photo</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>359000000000</td>\n      <td>公视粉丝团</td>\n      <td>电视频道</td>\n      <td>「再不救，就来不及了！如果没有很强力的救，再三十年，你可能找不到鹿港的味道了！」\\n\\n「两...</td>\n      <td>【我们的岛】抢救鹿港</td>\n      <td>叶明兰、叶镇中 / 采访报导 「再不救，就来不及了！如果没有很强力的救，再三十年，你可能找不...</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"./data/cda1_1.xlsx\")\n",
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_fl = data['分类'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "grp = data.pivot_table(index='主页ID', columns='y', values=['分类'], aggfunc='count').droplevel(0, axis=1)\n",
    "grp = grp.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "y                   H      L\n主页ID                        \n90420602485       0.0    3.0\n103000000000      0.0    4.0\n114000000000      0.0    5.0\n147000000000      0.0    4.0\n150000000000      0.0   16.0\n187000000000      0.0    8.0\n241000000000      0.0    3.0\n359000000000      0.0  376.0\n371000000000      0.0    9.0\n112000000000000   0.0    3.0\n114000000000000   0.0    4.0\n137000000000000   0.0    3.0\n147000000000000   0.0    6.0\n148000000000000   0.0    8.0\n154000000000000   0.0   35.0\n165000000000000   0.0    8.0\n180000000000000   0.0    3.0\n187000000000000   0.0   31.0\n197000000000000   0.0   62.0\n198000000000000   0.0    3.0\n240000000000000   0.0    4.0\n357000000000000   0.0    4.0\n410000000000000   0.0    4.0\n538000000000000   0.0   17.0\n575000000000000   0.0   17.0\n652000000000000   0.0    5.0\n720000000000000   0.0   11.0\n983000000000000   0.0  103.0\n1500000000000000  0.0   22.0\n1550000000000000  0.0    3.0\n1620000000000000  0.0   23.0\n1650000000000000  0.0  319.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>y</th>\n      <th>H</th>\n      <th>L</th>\n    </tr>\n    <tr>\n      <th>主页ID</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>90420602485</th>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>103000000000</th>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>114000000000</th>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>147000000000</th>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>150000000000</th>\n      <td>0.0</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>187000000000</th>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>241000000000</th>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>359000000000</th>\n      <td>0.0</td>\n      <td>376.0</td>\n    </tr>\n    <tr>\n      <th>371000000000</th>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>112000000000000</th>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>114000000000000</th>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>137000000000000</th>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>147000000000000</th>\n      <td>0.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>148000000000000</th>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>154000000000000</th>\n      <td>0.0</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>165000000000000</th>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>180000000000000</th>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>187000000000000</th>\n      <td>0.0</td>\n      <td>31.0</td>\n    </tr>\n    <tr>\n      <th>197000000000000</th>\n      <td>0.0</td>\n      <td>62.0</td>\n    </tr>\n    <tr>\n      <th>198000000000000</th>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>240000000000000</th>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>357000000000000</th>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>410000000000000</th>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>538000000000000</th>\n      <td>0.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>575000000000000</th>\n      <td>0.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>652000000000000</th>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>720000000000000</th>\n      <td>0.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>983000000000000</th>\n      <td>0.0</td>\n      <td>103.0</td>\n    </tr>\n    <tr>\n      <th>1500000000000000</th>\n      <td>0.0</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>1550000000000000</th>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1620000000000000</th>\n      <td>0.0</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>1650000000000000</th>\n      <td>0.0</td>\n      <td>319.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blacklist = grp[((grp['H'] == 0) & (grp['L'] > 2))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "whitelist = grp[(grp['L'] == 0) & (grp['H'] > 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "(6696, 8)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_remove_bw = data[(~data['主页ID'].isin(blacklist.index.values)) & (~data['主页ID'].isin(whitelist.index.values))]\n",
    "data_remove_bw.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "                 主页ID        主页名称    分类  \\\n5     242000000000000  ETtoday新闻云    新闻   \n7     109000000000000  Yahoo!奇摩新闻    新闻   \n9     109000000000000  Yahoo!奇摩新闻    新闻   \n10    261000000000000  ETtoday运动云    新闻   \n16    109000000000000  Yahoo!奇摩新闻    新闻   \n...               ...         ...   ...   \n7821  261000000000000  ETtoday运动云    新闻   \n7823     283000000000      中天快点TV  电视频道   \n7824     283000000000      中天快点TV  电视频道   \n7827  242000000000000  ETtoday新闻云    新闻   \n7828     128000000000        天下杂志  书籍杂志   \n\n                                                message  \\\n5     爽啦～～～（ Supermm）\\n\\n#中华队 #古巴\\nhttp://www.ettoda...   \n7     一个字，爽！！！！\\n\\n#12强 #台古大战 #林智胜 #棒球 #三分砲 Lamigo M...   \n9     这场比赛太感动了，你怎能不爱棒球！\\n\\n#12强 #中华队 #古巴  #林智胜 #棒球 #三分砲   \n10    大师兄轰了!!!!!!!!(KUBOTA)\\n\\nhttp://sports.ettoday...   \n16    不浪费时间吵架「因为我们连相爱的时间都太少」\\n\\n阳岱钢 DAIKAN YOH #12强 #棒球   \n...                                                 ...   \n7821  不管那么多啦！一直赢就对了！（59GO)\\n\\nhttp://sports.ettoday....   \n7823  这份礼物会让所有妈咪都很～羨～慕！(招弟)\\n\\n\\n隋棠 Sonia Sui\\n---\\n...   \n7824  被镶上绿色宝石的番薯，好美！（土星人）\\n\\n\\n---\\n●CH52中天新闻On Air！...   \n7827   快、合、作！（ Joe小姐）\\n\\n蔡依林 Jolin Tsai T.O.P. G-DRAGON   \n7828    【联合报】  一个班才2、3个人，大学班级变家教班？\\n\\n4系注册挂零、6校拉警报！！ ↓↓   \n\n                                                   name  \\\n5       故意保送后林智胜怒轰3分炮　中华睽违9年击败古巴 | ET运动云 | ETtoday东森新闻云   \n7                                世界12强／林智胜怒轰3分砲！中华队赢古巴啦   \n9                                世界12强／等了29年这么久 中华队再赢古巴   \n10         快讯／不让古巴看不起　林智胜8下怒轰3分砲 | ET运动云 | ETtoday东森新闻云   \n16                               给阳岱钢的情书 谢宛容：你是用生命爱我的男人   \n...                                                 ...   \n7821      中华抢8强对波多黎各非胜不可　连赢2场便晋级 | ET运动云 | ETtoday东森新闻云   \n7823                   2个月帅儿Max送「超大礼」　隋棠开心喊：似乎瞄到出运的曙光了！   \n7824                           从太空夜拍台湾美翻了！　嘉南平原就像被镶上绿宝石   \n7827  蔡依林、GD&T.O.P后台照曝光　甜呼：小爱心主人！ | 娱乐星光云 | ETtoday东...   \n7828                    注册率不到3成　大专67校系快灭顶｜教育｜联合新闻网｜天下杂志   \n\n                                            description  发文类型  y  \n5     世界12强棒球赛中华队林智胜，8局下在前一棒郭严文被故意保送成一、二垒有人，轰出左外野3分全...  link  H  \n7                             今天(14日)「大师兄」林智胜单场被看扁2次...  link  H  \n9     中华队今天(14日)写下历史性的一页，以4比1击败古巴队，这是相隔29年之久，再次于成人组顶...  link  H  \n10    12强中华队14日分组预赛对上古巴队，中华队派出宋家豪担任先发，前7局双方战成1比1平手，8...  link  H  \n16    两人的浪漫爱情故事最为人称羨。阳岱钢曾三次求婚，二○一○年底比赛中场、万名球迷见证下，阳岱钢...  link  H  \n...                                                 ...   ... ..  \n7821  世界12强中华队在预赛剩下2场比赛，14日对古巴、15日对波多黎各，对波多黎各的比赛一定要赢...  link  L  \n7823  隋棠8月顺利自然产下儿子Max，当时产后首次曝光的全身照仍超瘦，让许多人好羨慕！而昨晚Max...  link  L  \n7824  国际太空站拍下夜晚台湾，影片一上传，立刻受到热烈讨论，不少人都被台湾的美给吸引，?万家灯火构...  link  L  \n7827  「呸姊」蔡依林2日晚间出席南韩年度盛事MAMA舞台，她一开低胸紧身服装霸气登场，献唱舞曲《P...  link  L  \n7828  教育部昨公布104学年度大专校院各校系注册率，竟有高达67校系注册率不到3成，学生只有2、3...  link  L  \n\n[5309 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>主页ID</th>\n      <th>主页名称</th>\n      <th>分类</th>\n      <th>message</th>\n      <th>name</th>\n      <th>description</th>\n      <th>发文类型</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>242000000000000</td>\n      <td>ETtoday新闻云</td>\n      <td>新闻</td>\n      <td>爽啦～～～（ Supermm）\\n\\n#中华队 #古巴\\nhttp://www.ettoda...</td>\n      <td>故意保送后林智胜怒轰3分炮　中华睽违9年击败古巴 | ET运动云 | ETtoday东森新闻云</td>\n      <td>世界12强棒球赛中华队林智胜，8局下在前一棒郭严文被故意保送成一、二垒有人，轰出左外野3分全...</td>\n      <td>link</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>109000000000000</td>\n      <td>Yahoo!奇摩新闻</td>\n      <td>新闻</td>\n      <td>一个字，爽！！！！\\n\\n#12强 #台古大战 #林智胜 #棒球 #三分砲 Lamigo M...</td>\n      <td>世界12强／林智胜怒轰3分砲！中华队赢古巴啦</td>\n      <td>今天(14日)「大师兄」林智胜单场被看扁2次...</td>\n      <td>link</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>109000000000000</td>\n      <td>Yahoo!奇摩新闻</td>\n      <td>新闻</td>\n      <td>这场比赛太感动了，你怎能不爱棒球！\\n\\n#12强 #中华队 #古巴  #林智胜 #棒球 #三分砲</td>\n      <td>世界12强／等了29年这么久 中华队再赢古巴</td>\n      <td>中华队今天(14日)写下历史性的一页，以4比1击败古巴队，这是相隔29年之久，再次于成人组顶...</td>\n      <td>link</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>261000000000000</td>\n      <td>ETtoday运动云</td>\n      <td>新闻</td>\n      <td>大师兄轰了!!!!!!!!(KUBOTA)\\n\\nhttp://sports.ettoday...</td>\n      <td>快讯／不让古巴看不起　林智胜8下怒轰3分砲 | ET运动云 | ETtoday东森新闻云</td>\n      <td>12强中华队14日分组预赛对上古巴队，中华队派出宋家豪担任先发，前7局双方战成1比1平手，8...</td>\n      <td>link</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>109000000000000</td>\n      <td>Yahoo!奇摩新闻</td>\n      <td>新闻</td>\n      <td>不浪费时间吵架「因为我们连相爱的时间都太少」\\n\\n阳岱钢 DAIKAN YOH #12强 #棒球</td>\n      <td>给阳岱钢的情书 谢宛容：你是用生命爱我的男人</td>\n      <td>两人的浪漫爱情故事最为人称羨。阳岱钢曾三次求婚，二○一○年底比赛中场、万名球迷见证下，阳岱钢...</td>\n      <td>link</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7821</th>\n      <td>261000000000000</td>\n      <td>ETtoday运动云</td>\n      <td>新闻</td>\n      <td>不管那么多啦！一直赢就对了！（59GO)\\n\\nhttp://sports.ettoday....</td>\n      <td>中华抢8强对波多黎各非胜不可　连赢2场便晋级 | ET运动云 | ETtoday东森新闻云</td>\n      <td>世界12强中华队在预赛剩下2场比赛，14日对古巴、15日对波多黎各，对波多黎各的比赛一定要赢...</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>7823</th>\n      <td>283000000000</td>\n      <td>中天快点TV</td>\n      <td>电视频道</td>\n      <td>这份礼物会让所有妈咪都很～羨～慕！(招弟)\\n\\n\\n隋棠 Sonia Sui\\n---\\n...</td>\n      <td>2个月帅儿Max送「超大礼」　隋棠开心喊：似乎瞄到出运的曙光了！</td>\n      <td>隋棠8月顺利自然产下儿子Max，当时产后首次曝光的全身照仍超瘦，让许多人好羨慕！而昨晚Max...</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>7824</th>\n      <td>283000000000</td>\n      <td>中天快点TV</td>\n      <td>电视频道</td>\n      <td>被镶上绿色宝石的番薯，好美！（土星人）\\n\\n\\n---\\n●CH52中天新闻On Air！...</td>\n      <td>从太空夜拍台湾美翻了！　嘉南平原就像被镶上绿宝石</td>\n      <td>国际太空站拍下夜晚台湾，影片一上传，立刻受到热烈讨论，不少人都被台湾的美给吸引，?万家灯火构...</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>7827</th>\n      <td>242000000000000</td>\n      <td>ETtoday新闻云</td>\n      <td>新闻</td>\n      <td>快、合、作！（ Joe小姐）\\n\\n蔡依林 Jolin Tsai T.O.P. G-DRAGON</td>\n      <td>蔡依林、GD&amp;T.O.P后台照曝光　甜呼：小爱心主人！ | 娱乐星光云 | ETtoday东...</td>\n      <td>「呸姊」蔡依林2日晚间出席南韩年度盛事MAMA舞台，她一开低胸紧身服装霸气登场，献唱舞曲《P...</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>7828</th>\n      <td>128000000000</td>\n      <td>天下杂志</td>\n      <td>书籍杂志</td>\n      <td>【联合报】  一个班才2、3个人，大学班级变家教班？\\n\\n4系注册挂零、6校拉警报！！ ↓↓</td>\n      <td>注册率不到3成　大专67校系快灭顶｜教育｜联合新闻网｜天下杂志</td>\n      <td>教育部昨公布104学年度大专校院各校系注册率，竟有高达67校系注册率不到3成，学生只有2、3...</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n<p>5309 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_remove_bw[~data_remove_bw['description'].isnull()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1909\n"
     ]
    }
   ],
   "source": [
    "stop_words = []\n",
    "with open(\"./data/stop_words.txt\", \"r\", encoding='utf-8') as f_stopwords:\n",
    "    for line in f_stopwords:\n",
    "        line = line.replace(\"\\r\", \"\").replace(\"\\n\", \"\").strip()\n",
    "        stop_words.append(line)\n",
    "stop_words = set(stop_words)\n",
    "print(len(stop_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\proffl\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.199 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姊 蔡依林 日 晚间 出席 南韩 年度 盛事 舞台 一开 低胸 紧身 服装 霸气 登场 献唱 舞曲\n"
     ]
    }
   ],
   "source": [
    "def split_word(document):\n",
    "    import jieba\n",
    "    import re\n",
    "    if document is None or type(document) is float:\n",
    "        return \"\"\n",
    "    chinese_regular = u\"([\\u4e00-\\u9fa5]+)\"\n",
    "    pattern = re.compile(chinese_regular)\n",
    "    jieba.add_word(\"林智胜\")\n",
    "    jieba.add_word(\"郭严文\")\n",
    "    jieba.add_word(\"蔡依林\")\n",
    "    li = \" \".join(jieba.cut(document))\n",
    "    vocabulary = []\n",
    "    chinese_only = pattern.findall(li)\n",
    "    if chinese_only is not None and len(chinese_only) >= 1:\n",
    "\n",
    "        for word in chinese_only:\n",
    "            if word not in stop_words:\n",
    "                vocabulary.append(word)\n",
    "    return \" \".join(vocabulary)\n",
    "\n",
    "\n",
    "print(split_word(\"「呸姊」蔡依林2日晚间出席南韩年度盛事MAMA舞台，她一开低胸紧身服装霸气登场，献唱舞曲《P...\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0                                                        \n1       这是 资讯 爆炸 时代 选择 资讯 视野 选择 电视频道 将会 未来 公视 电视 募款 公视...\n2                                                        \n3                                                        \n4       叶明兰 叶镇 采访 报导 不救 强力 救 三十年 找 不到 鹿港 味道 两百年 老房子 消失...\n                              ...                        \n7824    国际 太空站 拍下 夜晚 台湾 影片 上传 热烈 讨论 台湾 美 吸引 万家灯火 构筑 美景...\n7825                                                     \n7826                                                     \n7827    姊 蔡依林 日 晚间 出席 南韩 年度 盛事 舞台 一开 低胸 紧身 服装 霸气 登场 献唱...\n7828    教育部 昨 公布 学年度 大专 校院 各校 系 注册 率 竟有 高达 校系 注册 率 不到 ...\nName: sp_msg, Length: 7829, dtype: object"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sp_msg'] = data['description'].apply(lambda doc: split_word(doc))\n",
    "#data['sp_msg'].to_csv('lines.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "data[data['sp_msg'].map(lambda x: len(x) >= 2)]['sp_msg'].to_csv('lines.csv', index=False, header=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sp_msg'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3079\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3080\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3081\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'sp_msg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-d30a2f574396>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_extraction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTfidfVectorizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mtfidf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTfidfVectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtfidf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'sp_msg'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtfidf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_feature_names\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3022\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3023\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3024\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3025\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3026\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3080\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3081\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3082\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3084\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'sp_msg'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "x = tfidf.fit_transform(data['sp_msg'])\n",
    "df = pd.DataFrame(x.toarray(), columns=tfidf.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "      发文类型_0  发文类型_1  发文类型_2\n0        0.0     0.0     1.0\n1        0.0     0.0     1.0\n2        1.0     0.0     0.0\n3        0.0     1.0     0.0\n4        1.0     0.0     0.0\n...      ...     ...     ...\n7824     1.0     0.0     0.0\n7825     0.0     1.0     0.0\n7826     0.0     1.0     0.0\n7827     1.0     0.0     0.0\n7828     1.0     0.0     0.0\n\n[7829 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>发文类型_0</th>\n      <th>发文类型_1</th>\n      <th>发文类型_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7824</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7825</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7826</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7827</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7828</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7829 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encoder_column(input_df, column_name, label_mapping, fill_na=0, column_names=None):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    mapped_df = input_df[column_name].map(label_mapping).fillna(fill_na).astype(int)\n",
    "    ohe_encoder = OneHotEncoder(drop='first')\n",
    "    ohe_arr = ohe_encoder.fit_transform(mapped_df.values.reshape(-1,1))\n",
    "    if column_names is None:\n",
    "        column_names = [\"_\".join([column_name, str(i)]) for i in range(0, ohe_arr.shape[1])]\n",
    "    ohe_df = pd.DataFrame(ohe_arr.toarray(), columns=column_names)\n",
    "    return ohe_df, ohe_encoder\n",
    "\n",
    "cat_type_map = {'新闻': 1, '电视频道': 2, '书籍杂志': 3, '节目': 4,\n",
    "                '电视剧': 5, '媒体其他': 6, '网路社群': 7, '电影公司': 8,\n",
    "                '电影': 8, '广播': 6, '音乐': 6, '电影相关活动': 8}\n",
    "data_cat, ohe_cat = one_hot_encoder_column(data, '分类', cat_type_map, fill_na=0)\n",
    "doc_type_map = {'link': 1, 'photo': 2, 'video': 3}\n",
    "data_doc_type, ohe_doc_type = one_hot_encoder_column(data, '发文类型', doc_type_map, fill_na=0)\n",
    "data_doc_type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "data['message'] = data['message'].fillna(\"\")\n",
    "data['name'] = data['name'].fillna(\"\")\n",
    "data['description'] = data['description'].fillna(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "data_doc_all = data['message'] + data['name'] + data['description']\n",
    "data_doc_splited = [split_word(doc) for doc in data_doc_all]\n",
    "data_doc_splited"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\anaconda\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\gensim\\models\\word2vec.py\", line 1162, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\gensim\\models\\word2vec.py\", line 953, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim\\models\\word2vec_inner.pyx\", line 653, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "TypeError: Cannot convert list to numpy.ndarray\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "sentences = word2vec.LineSentence(\"./lines.csv\")\n",
    "model = word2vec.Word2Vec(sentences, hs=1, min_count=5, window=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "saved = pd.DataFrame(data_doc_splited)\n",
    "saved.to_csv(\"lines.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}