{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "              主页ID        主页名称    分类  \\\n0  155000000000000  纬来体育台官方粉丝团  电视频道   \n1     359000000000       公视粉丝团  电视频道   \n2     359000000000       公视粉丝团  电视频道   \n3     190000000000    Mobile01  网路社群   \n4     359000000000       公视粉丝团  电视频道   \n\n                                             message                    name  \\\n0                      中华队长林智胜 三分砲！！！\\n人如其名　真的「致胜」阿～                     NaN   \n1    您所选择的电视频道，将会决定您的未来~\\n遥控器的决定权，就在你手上！\\n\\n#看见更好的未来  2015公视电视募款 公视让你看见更好的未来   \n2  好演员值得更多肯定和掌声！\\n\\n吴慷仁提到大概有六、七年资历的演员，所面临的最大困境，是赚...                   公视粉丝团   \n3                              大师兄 一发炸裂！！帅啊啊啊啊啊啊啊！！！       来自 Mobile01 贴文的相片   \n4  「再不救，就来不及了！如果没有很强力的救，再三十年，你可能找不到鹿港的味道了！」\\n\\n「两...              【我们的岛】抢救鹿港   \n\n                                         description   发文类型  y  \n0                                                NaN  video  H  \n1  这是一个资讯爆炸的时代，你所选择的资讯将决定你的视野；你所选择的电视频道，将会决定你的未来 ...  video  L  \n2                                                NaN   link  L  \n3                                                NaN  photo  H  \n4  叶明兰、叶镇中 / 采访报导 「再不救，就来不及了！如果没有很强力的救，再三十年，你可能找不...   link  L  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>主页ID</th>\n      <th>主页名称</th>\n      <th>分类</th>\n      <th>message</th>\n      <th>name</th>\n      <th>description</th>\n      <th>发文类型</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>155000000000000</td>\n      <td>纬来体育台官方粉丝团</td>\n      <td>电视频道</td>\n      <td>中华队长林智胜 三分砲！！！\\n人如其名　真的「致胜」阿～</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>video</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>359000000000</td>\n      <td>公视粉丝团</td>\n      <td>电视频道</td>\n      <td>您所选择的电视频道，将会决定您的未来~\\n遥控器的决定权，就在你手上！\\n\\n#看见更好的未来</td>\n      <td>2015公视电视募款 公视让你看见更好的未来</td>\n      <td>这是一个资讯爆炸的时代，你所选择的资讯将决定你的视野；你所选择的电视频道，将会决定你的未来 ...</td>\n      <td>video</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>359000000000</td>\n      <td>公视粉丝团</td>\n      <td>电视频道</td>\n      <td>好演员值得更多肯定和掌声！\\n\\n吴慷仁提到大概有六、七年资历的演员，所面临的最大困境，是赚...</td>\n      <td>公视粉丝团</td>\n      <td>NaN</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>190000000000</td>\n      <td>Mobile01</td>\n      <td>网路社群</td>\n      <td>大师兄 一发炸裂！！帅啊啊啊啊啊啊啊！！！</td>\n      <td>来自 Mobile01 贴文的相片</td>\n      <td>NaN</td>\n      <td>photo</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>359000000000</td>\n      <td>公视粉丝团</td>\n      <td>电视频道</td>\n      <td>「再不救，就来不及了！如果没有很强力的救，再三十年，你可能找不到鹿港的味道了！」\\n\\n「两...</td>\n      <td>【我们的岛】抢救鹿港</td>\n      <td>叶明兰、叶镇中 / 采访报导 「再不救，就来不及了！如果没有很强力的救，再三十年，你可能找不...</td>\n      <td>link</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"./data/1_train.xlsx\")\n",
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grp = data.pivot_table(index='主页ID', columns='y', values=['分类'], aggfunc='count').droplevel(0, axis=1)\n",
    "grp = grp.fillna(0)\n",
    "blacklist = grp[ ((grp['H'] <= 1) & (grp['L'] >5)) ]\n",
    "whitelist = grp[ (grp['L'] == 0) & (grp['H'] > 1) ]\n",
    "data_remove_bw = data[ (~data['主页ID'].isin(blacklist.index.values)) &\n",
    "                       (~data['主页ID'].isin(whitelist.index.values)) ]\n",
    "data_remove_bw = data_remove_bw.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts50 = grp[(grp['H'] + grp['L'])>=50]\n",
    "counts50['hl_score'] = np.log2(counts50['H'] + 0.1) / np.log2(counts50['H'] + counts50['L'] + 0.1)\n",
    "data_tmp = pd.merge(data_remove_bw, counts50, how='left', on='主页ID')\n",
    "data_hl_score = data_tmp['hl_score'].fillna(0)\n",
    "data_hl_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_remove_bw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-28a50d761dee>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m fl_mapping = {'电视频道': 0, '网路社群': 1, '新闻': 2, '书籍杂志': 3, '电视剧': 4, '电影公司': 5, \" \\\n\u001B[1;32m      3\u001B[0m              \"'节目': 6, '媒体其他': 7, '电影': 5, '音乐': 7, '电影相关活动': 5, '广播': 7}\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mdata_fl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfl_ohe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mone_hot_encoder_column\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_remove_bw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'分类'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfl_mapping\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfill_na\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m7\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mdata_fl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_fl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mdata_fl\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_remove_bw' is not defined"
     ]
    }
   ],
   "source": [
    "from Python.pandas.feature_selection import *\n",
    "fl_mapping = {'电视频道': 0, '网路社群': 1, '新闻': 2, '书籍杂志': 3, '电视剧': 4, '电影公司': 5, \" \\\n",
    "             \"'节目': 6, '媒体其他': 7, '电影': 5, '音乐': 7, '电影相关活动': 5, '广播': 7}\n",
    "data_fl, fl_ohe = one_hot_encoder_column(data_remove_bw, '分类', fl_mapping, fill_na=7)\n",
    "data_fl = pd.DataFrame(data_fl)\n",
    "data_fl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc_type_map = {'link': 1, 'photo': 2, 'video': 3}\n",
    "data_doc_type, ohe_doc_type = one_hot_encoder_column(data_remove_bw, '发文类型', doc_type_map, fill_na=3)\n",
    "data_doc_type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Python.nlp.nlp import *\n",
    "stop_words = get_stop_words('./data/stop_words.txt', encoding='utf-8')\n",
    "data_all = data.apply(lambda x: split_word(\n",
    "    str(x['message']) + str(x['name']) + str(x['description']),\n",
    "    stop_words, ['蔡依林', '叶明兰','叶镇中', '宋家豪', '白先勇','林智胜']),\n",
    "                      axis=1)\n",
    "\n",
    "data_all.to_csv(\"data/lines.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data['nosplit'] = data.apply(lambda x: str(x['message']) + str(x['name']) + str(x['description']), axis=1)\n",
    "#data_nosplit.to_csv(\"data/no_lines.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from ltp import LTP\n",
    "ltp = LTP(path=\"/Users/proffl/nltk_data/small\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['中华队长', '林智胜', '三分砲', '！', '！', '！', '人如其名\\u3000真的', '「', '致胜', '」', '阿～nanna', '。']]\n",
      "[['ni', 'nh', 'n', 'wp', 'wp', 'wp', 'i', 'wp', 'v', 'wp', 'nh', 'wp']]\n",
      "[[('Ni', 0, 0), ('Nh', 1, 1), ('Nh', 10, 10)]]\n"
     ]
    }
   ],
   "source": [
    "seg, hidden = ltp.seg([\"中华队长林智胜 三分砲！！！\\n人如其名\\u3000真的「致胜」阿～nanna。\"])\n",
    "pos = ltp.pos(hidden) # 词性标注\n",
    "ner = ltp.ner(hidden) # 命名实体识别\n",
    "srl = ltp.srl(hidden) # 语义角色标注\n",
    "dep = ltp.dep(hidden) # 依存句法分析\n",
    "sdp = ltp.sdp(hidden) # 语义依存分析(树)\n",
    "# sdp = ltp.sdp(hidden, mode='graph')  # 语义依存分析(图)\n",
    "print(seg)\n",
    "print(pos)\n",
    "print(ner)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seg, hidden = ltp.seg(data['nosplit'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'nosplit'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3079\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3080\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3081\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'nosplit'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-019ddfbbfeca>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mall_words\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mdoc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'nosplit'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mseg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhidden\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mltp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mpos\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mltp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mwords\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3022\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3023\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3024\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3025\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3026\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3080\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3081\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3082\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3084\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'nosplit'"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for doc in data['nosplit'].tolist():\n",
    "    seg, hidden = ltp.seg([doc])\n",
    "    pos = ltp.pos(hidden)[0]\n",
    "    words = []\n",
    "    for (idx, p) in enumerate(pos):\n",
    "        if p.startswith('n'):\n",
    "            words.append(seg[0][idx])\n",
    "    all_words.append(words)\n",
    "all_words[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['nosplit'].tolist()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_nosplit = data.apply(lambda x: str(x['message']) + str(x['name']) + str(x['description']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_nosplit = data_nosplit.tolist()\n",
    "data_nosplit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seg, hidden = ltp.seg(data_nosplit[:10])\n",
    "ner = ltp.ner(hidden)\n",
    "ner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keys = set()\n",
    "for doc in data_nosplit:\n",
    "    doc_split = doc.split(\"#\")\n",
    "    if len(doc_split)> 1:\n",
    "        for s in doc_split[1:]:\n",
    "            if len(s.strip()) < 8:\n",
    "                keys.add(s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_all = data.apply(lambda x: split_word(\n",
    "    str(x['message']) + str(x['name']) + str(x['description']),\n",
    "    stop_words, keys),axis=1)\n",
    "data_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}