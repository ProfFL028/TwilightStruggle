{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import stats\n",
    "\n",
    "import gc\n",
    "from collections import Counter\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# reduce memory\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024 / 1024\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem-end_mem)/start_mem))\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1.74 MB\n",
      "Decreased by 70.8%\n",
      "Memory usage after optimization is: 3.49 MB\n",
      "Decreased by 41.7%\n",
      "Memory usage after optimization is: 3.24 MB\n",
      "Decreased by 66.7%\n",
      "Memory usage after optimization is: 890.48 MB\n",
      "Decreased by 69.6%\n"
     ]
    }
   ],
   "source": [
    "num_rows = None\n",
    "\n",
    "test_data = pd.read_csv('./test_format1.csv')\n",
    "train_data = pd.read_csv('./train_format1.csv')\n",
    "user_info = pd.read_csv('./user_info_format1.csv')\n",
    "user_log = pd.read_csv('./user_log_format1.csv')\n",
    "\n",
    "train_data = reduce_mem_usage(train_data, verbose=True)\n",
    "test_data = reduce_mem_usage(test_data, verbose=True)\n",
    "user_info = reduce_mem_usage(user_info, verbose=True)\n",
    "user_log = reduce_mem_usage(user_log, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260864 entries, 0 to 260863\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype\n",
      "---  ------       --------------   -----\n",
      " 0   user_id      260864 non-null  int32\n",
      " 1   merchant_id  260864 non-null  int16\n",
      " 2   label        260864 non-null  int8 \n",
      "dtypes: int16(1), int32(1), int8(1)\n",
      "memory usage: 1.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261477 entries, 0 to 261476\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   user_id      261477 non-null  int32  \n",
      " 1   merchant_id  261477 non-null  int16  \n",
      " 2   prob         0 non-null       float64\n",
      "dtypes: float64(1), int16(1), int32(1)\n",
      "memory usage: 3.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424170 entries, 0 to 424169\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    424170 non-null  int32  \n",
      " 1   age_range  421953 non-null  float16\n",
      " 2   gender     417734 non-null  float16\n",
      "dtypes: float16(2), int32(1)\n",
      "memory usage: 3.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54925330 entries, 0 to 54925329\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   user_id      int32  \n",
      " 1   item_id      int32  \n",
      " 2   cat_id       int16  \n",
      " 3   seller_id    int16  \n",
      " 4   brand_id     float16\n",
      " 5   time_stamp   int16  \n",
      " 6   action_type  int8   \n",
      "dtypes: float16(1), int16(3), int32(2), int8(1)\n",
      "memory usage: 890.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "test_data.info()\n",
    "user_info.info()\n",
    "user_log.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "9418"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = train_data.append(test_data)\n",
    "all_data = all_data.merge(user_info, on=['user_id'], how='left')\n",
    "del train_data, test_data, user_info\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "          user_id  item_id  cat_id  seller_id  brand_id  time_stamp  \\\n23288890        1   181459     276       2245    4752.0        1009   \n23288891        1   779078     276       2245    4752.0        1009   \n23288892        1   779078     276       2245    4752.0        1009   \n23288893        1   452837     276       2245    4752.0        1009   \n23288894        1   543397     276       2245    4752.0        1009   \n...           ...      ...     ...        ...       ...         ...   \n13710705   424170   416729     602       3736    3124.0        1111   \n13710706   424170   424015     761        525    5444.0        1111   \n13710707   424170   802762     602       3736    3124.0        1111   \n13710714   424170   795753     656       4268    1642.0        1111   \n13710715   424170   365302     761       3736    3124.0        1111   \n\n          action_type  \n23288890            0  \n23288891            0  \n23288892            0  \n23288893            0  \n23288894            0  \n...               ...  \n13710705            0  \n13710706            0  \n13710707            0  \n13710714            2  \n13710715            0  \n\n[54925330 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>cat_id</th>\n      <th>seller_id</th>\n      <th>brand_id</th>\n      <th>time_stamp</th>\n      <th>action_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23288890</th>\n      <td>1</td>\n      <td>181459</td>\n      <td>276</td>\n      <td>2245</td>\n      <td>4752.0</td>\n      <td>1009</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23288891</th>\n      <td>1</td>\n      <td>779078</td>\n      <td>276</td>\n      <td>2245</td>\n      <td>4752.0</td>\n      <td>1009</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23288892</th>\n      <td>1</td>\n      <td>779078</td>\n      <td>276</td>\n      <td>2245</td>\n      <td>4752.0</td>\n      <td>1009</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23288893</th>\n      <td>1</td>\n      <td>452837</td>\n      <td>276</td>\n      <td>2245</td>\n      <td>4752.0</td>\n      <td>1009</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23288894</th>\n      <td>1</td>\n      <td>543397</td>\n      <td>276</td>\n      <td>2245</td>\n      <td>4752.0</td>\n      <td>1009</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13710705</th>\n      <td>424170</td>\n      <td>416729</td>\n      <td>602</td>\n      <td>3736</td>\n      <td>3124.0</td>\n      <td>1111</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13710706</th>\n      <td>424170</td>\n      <td>424015</td>\n      <td>761</td>\n      <td>525</td>\n      <td>5444.0</td>\n      <td>1111</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13710707</th>\n      <td>424170</td>\n      <td>802762</td>\n      <td>602</td>\n      <td>3736</td>\n      <td>3124.0</td>\n      <td>1111</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13710714</th>\n      <td>424170</td>\n      <td>795753</td>\n      <td>656</td>\n      <td>4268</td>\n      <td>1642.0</td>\n      <td>1111</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13710715</th>\n      <td>424170</td>\n      <td>365302</td>\n      <td>761</td>\n      <td>3736</td>\n      <td>3124.0</td>\n      <td>1111</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>54925330 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log = user_log.sort_values(['user_id', 'time_stamp'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "        user_id  merchant_id  label  prob  age_range  gender  \\\n0         34176         3906    0.0   NaN        6.0     0.0   \n1         34176          121    0.0   NaN        6.0     0.0   \n2         34176         4356    1.0   NaN        6.0     0.0   \n3         34176         2217    0.0   NaN        6.0     0.0   \n4        230784         4818    0.0   NaN        0.0     0.0   \n...         ...          ...    ...   ...        ...     ...   \n522336   228479         3111    NaN   NaN        6.0     0.0   \n522337    97919         2341    NaN   NaN        8.0     1.0   \n522338    97919         3971    NaN   NaN        8.0     1.0   \n522339    32639         3536    NaN   NaN        0.0     0.0   \n522340    32639         3319    NaN   NaN        0.0     0.0   \n\n                                                item_path  \\\n0       581818 879005 581818 581818 1011673 52343 2773...   \n1       581818 879005 581818 581818 1011673 52343 2773...   \n2       581818 879005 581818 581818 1011673 52343 2773...   \n3       581818 879005 581818 581818 1011673 52343 2773...   \n4       191923 191923 191923 191923 964906 229470 2294...   \n...                                                   ...   \n522336  802791 977305 351177 122937 21972 863063 10903...   \n522337  484765 128769 128769 995386 128769 645625 9953...   \n522338  484765 128769 128769 995386 128769 645625 9953...   \n522339  394570 394570 394570 28017 110194 314126 95836...   \n522340  394570 394570 394570 28017 110194 314126 95836...   \n\n                                                 cat_path  \\\n0       1505 662 1505 1505 1505 662 1095 1505 662 1095...   \n1       1505 662 1505 1505 1505 662 1095 1505 662 1095...   \n2       1505 662 1505 1505 1505 662 1095 1505 662 1095...   \n3       1505 662 1505 1505 1505 662 1095 1505 662 1095...   \n4       1023 1023 1023 1023 662 664 664 1544 664 662 6...   \n...                                                   ...   \n522336  602 602 602 602 552 1271 1271 662 662 821 662 ...   \n522337  737 464 464 464 464 464 464 464 464 464 464 46...   \n522338  737 464 464 464 464 464 464 464 464 464 464 46...   \n522339  1413 1413 1413 812 1271 1271 1271 1198 1271 11...   \n522340  1413 1413 1413 812 1271 1271 1271 1198 1271 11...   \n\n                                              seller_path  \\\n0       416 3606 416 416 416 3760 3606 416 1926 3004 4...   \n1       416 3606 416 416 416 3760 3606 416 1926 3004 4...   \n2       416 3606 416 416 416 3760 3606 416 1926 3004 4...   \n3       416 3606 416 416 416 3760 3606 416 1926 3004 4...   \n4       3545 3545 3545 3545 4566 2537 2537 2420 2537 4...   \n...                                                   ...   \n522336  2823 2823 2664 2664 1076 2946 2781 4949 2412 4...   \n522337  4408 235 235 235 235 3416 235 235 235 235 235 ...   \n522338  4408 235 235 235 235 3416 235 235 235 235 235 ...   \n522339  1065 1065 1065 1506 38 1890 2280 4873 2280 487...   \n522340  1065 1065 1065 1506 38 1890 2280 4873 2280 487...   \n\n                                               brand_path  \\\n0       4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...   \n1       4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...   \n2       4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...   \n3       4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...   \n4       5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...   \n...                                                   ...   \n522336  1128.0 1128.0 8152.0 8152.0 3548.0 5560.0 3304...   \n522337  6968.0 2020.0 2020.0 2020.0 2020.0 6240.0 2020...   \n522338  6968.0 2020.0 2020.0 2020.0 2020.0 6240.0 2020...   \n522339  6376.0 4468.0 6376.0 4888.0 7008.0 5684.0 5372...   \n522340  6376.0 4468.0 6376.0 4888.0 7008.0 5684.0 5372...   \n\n                                          time_stamp_path  \\\n0       521 521 521 521 521 521 521 521 521 521 521 52...   \n1       521 521 521 521 521 521 521 521 521 521 521 52...   \n2       521 521 521 521 521 521 521 521 521 521 521 52...   \n3       521 521 521 521 521 521 521 521 521 521 521 52...   \n4       601 601 601 601 614 614 614 614 614 614 618 61...   \n...                                                   ...   \n522336  511 511 512 512 512 516 516 521 521 521 521 52...   \n522337  626 707 707 710 710 710 710 710 710 710 710 71...   \n522338  626 707 707 710 710 710 710 710 710 710 710 71...   \n522339  523 523 523 525 617 617 723 723 723 723 807 81...   \n522340  523 523 523 525 617 617 723 723 723 723 807 81...   \n\n                                         action_type_path  \n0       0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...  \n1       0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...  \n2       0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...  \n3       0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...  \n4       0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...  \n...                                                   ...  \n522336  3 3 2 2 2 3 3 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 ...  \n522337  2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 3 ...  \n522338  2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 3 ...  \n522339  0 2 0 0 0 0 0 0 0 2 0 0 0 0 2 0 2 0 0 3 0 0 0 ...  \n522340  0 2 0 0 0 0 0 0 0 2 0 0 0 0 2 0 2 0 0 3 0 0 0 ...  \n\n[522341 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>merchant_id</th>\n      <th>label</th>\n      <th>prob</th>\n      <th>age_range</th>\n      <th>gender</th>\n      <th>item_path</th>\n      <th>cat_path</th>\n      <th>seller_path</th>\n      <th>brand_path</th>\n      <th>time_stamp_path</th>\n      <th>action_type_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34176</td>\n      <td>3906</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34176</td>\n      <td>121</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34176</td>\n      <td>4356</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34176</td>\n      <td>2217</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>230784</td>\n      <td>4818</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>522336</th>\n      <td>228479</td>\n      <td>3111</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>802791 977305 351177 122937 21972 863063 10903...</td>\n      <td>602 602 602 602 552 1271 1271 662 662 821 662 ...</td>\n      <td>2823 2823 2664 2664 1076 2946 2781 4949 2412 4...</td>\n      <td>1128.0 1128.0 8152.0 8152.0 3548.0 5560.0 3304...</td>\n      <td>511 511 512 512 512 516 516 521 521 521 521 52...</td>\n      <td>3 3 2 2 2 3 3 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n    </tr>\n    <tr>\n      <th>522337</th>\n      <td>97919</td>\n      <td>2341</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>484765 128769 128769 995386 128769 645625 9953...</td>\n      <td>737 464 464 464 464 464 464 464 464 464 464 46...</td>\n      <td>4408 235 235 235 235 3416 235 235 235 235 235 ...</td>\n      <td>6968.0 2020.0 2020.0 2020.0 2020.0 6240.0 2020...</td>\n      <td>626 707 707 710 710 710 710 710 710 710 710 71...</td>\n      <td>2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 3 ...</td>\n    </tr>\n    <tr>\n      <th>522338</th>\n      <td>97919</td>\n      <td>3971</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>484765 128769 128769 995386 128769 645625 9953...</td>\n      <td>737 464 464 464 464 464 464 464 464 464 464 46...</td>\n      <td>4408 235 235 235 235 3416 235 235 235 235 235 ...</td>\n      <td>6968.0 2020.0 2020.0 2020.0 2020.0 6240.0 2020...</td>\n      <td>626 707 707 710 710 710 710 710 710 710 710 71...</td>\n      <td>2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 3 ...</td>\n    </tr>\n    <tr>\n      <th>522339</th>\n      <td>32639</td>\n      <td>3536</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>394570 394570 394570 28017 110194 314126 95836...</td>\n      <td>1413 1413 1413 812 1271 1271 1271 1198 1271 11...</td>\n      <td>1065 1065 1065 1506 38 1890 2280 4873 2280 487...</td>\n      <td>6376.0 4468.0 6376.0 4888.0 7008.0 5684.0 5372...</td>\n      <td>523 523 523 525 617 617 723 723 723 723 807 81...</td>\n      <td>0 2 0 0 0 0 0 0 0 2 0 0 0 0 2 0 2 0 0 3 0 0 0 ...</td>\n    </tr>\n    <tr>\n      <th>522340</th>\n      <td>32639</td>\n      <td>3319</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>394570 394570 394570 28017 110194 314126 95836...</td>\n      <td>1413 1413 1413 812 1271 1271 1271 1198 1271 11...</td>\n      <td>1065 1065 1065 1506 38 1890 2280 4873 2280 487...</td>\n      <td>6376.0 4468.0 6376.0 4888.0 7008.0 5684.0 5372...</td>\n      <td>523 523 523 525 617 617 723 723 723 723 807 81...</td>\n      <td>0 2 0 0 0 0 0 0 0 2 0 0 0 0 2 0 2 0 0 3 0 0 0 ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>522341 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_join_func = lambda x: \" \".join([str(i) for i in x])\n",
    "agg_dict = {\n",
    "    'item_id': list_join_func,\n",
    "    'cat_id': list_join_func,\n",
    "    'seller_id': list_join_func,\n",
    "    'brand_id': list_join_func,\n",
    "    'time_stamp': list_join_func,\n",
    "    'action_type': list_join_func\n",
    "}\n",
    "\n",
    "rename_dict = {\n",
    "    'item_id': 'item_path',\n",
    "    'cat_id': 'cat_path',\n",
    "    'seller_id': 'seller_path',\n",
    "    'brand_id': 'brand_path',\n",
    "    'time_stamp': 'time_stamp_path',\n",
    "    'action_type': 'action_type_path'\n",
    "}\n",
    "\n",
    "def merge_list(df_ID, join_columns, df_data, agg_dict, rename_dict):\n",
    "    df_data = df_data.groupby(join_columns).agg(agg_dict).reset_index().rename(columns=rename_dict)\n",
    "    df_ID = df_ID.merge(df_data, on=join_columns, how=\"left\")\n",
    "    return df_ID\n",
    "all_data = merge_list(all_data, 'user_id', user_log, agg_dict, rename_dict)\n",
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "1678"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del user_log\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def cnt_(x):\n",
    "    try:\n",
    "        return len(x.split(' '))\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def unique_(x):\n",
    "    try:\n",
    "        return len(set(x.split(' ')))\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def max_(x):\n",
    "    try:\n",
    "        return np.max([float(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def min_(x):\n",
    "    try:\n",
    "        return np.min([float(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def std_(x):\n",
    "    try:\n",
    "        return np.std([float(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def most_n(x, n):\n",
    "    try:\n",
    "        return Counter(x.split(' ')).most_common(n)[n-1][0]\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def most_n_cnt(x, n):\n",
    "    try:\n",
    "        return Counter(x.split(' ')).most_common(n)[n-1][1]\n",
    "    except:\n",
    "        return -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def user_cnt(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(cnt_)\n",
    "    return df_data\n",
    "\n",
    "def user_unique(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(unique_)\n",
    "    return df_data\n",
    "\n",
    "def user_max(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(max_)\n",
    "    return df_data\n",
    "\n",
    "def user_min(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(min_)\n",
    "    return df_data\n",
    "\n",
    "def user_std(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(std_)\n",
    "    return df_data\n",
    "\n",
    "def user_most_n(df_data, single_col, name, n=1):\n",
    "    func = lambda x: most_n(x, n)\n",
    "    df_data[name] = df_data[single_col].apply(func)\n",
    "    return df_data\n",
    "\n",
    "def user_most_n_cnt(df_data, single_col, name, n=1):\n",
    "    func = lambda x: most_n_cnt(x, n)\n",
    "    df_data[name] = df_data[single_col].apply(func)\n",
    "    return df_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#特征提取\n",
    "all_data_test = all_data.head(2000)\n",
    "all_data_test = user_cnt(all_data_test, 'seller_path', 'user_cnt')\n",
    "all_data_test = user_unique(all_data_test, 'seller_path', 'seller_unique')\n",
    "all_data_test = user_unique(all_data_test, 'cat_path', 'cat_unique')\n",
    "all_data_test = user_unique(all_data_test, 'brand_path', 'brand_unique')\n",
    "all_data_test = user_unique(all_data_test, 'item_path', 'item_unique')\n",
    "all_data_test = user_unique(all_data_test, 'time_stamp_path', 'time_unique')\n",
    "all_data_test = user_unique(all_data_test, 'action_type_path', 'action_type_unique')\n",
    "all_data_test = user_max(all_data_test, 'action_type_path', 'time_stamp_max')\n",
    "all_data_test = user_min(all_data_test, 'action_type_path', 'time_stamp_min')\n",
    "all_data_test = user_std(all_data_test, 'action_type_path', 'time_stamp_std')\n",
    "all_data_test['time_stamp_range'] = all_data_test['time_stamp_max'] - all_data_test['time_stamp_min']\n",
    "all_data_test = user_most_n(all_data_test, 'seller_path', 'seller_most_1', n=1)\n",
    "all_data_test = user_most_n(all_data_test, 'cat_path', 'cat_most_1', n=1)\n",
    "all_data_test = user_most_n(all_data_test, 'brand_path', 'brand_most_1', n=1)\n",
    "all_data_test = user_most_n(all_data_test, 'action_type_path', 'action_type_1', n=1)\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'seller_path', 'seller_most_1_cnt', n=1)\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'cat_path', 'cat_most_1_cnt', n=1)\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'brand_path', 'brand_most_1_cnt', n=1)\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'action_type_path', 'action_type_1_cnt', n=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def col_cnt_(df_data, columns_list, action_type):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "        col_list = copy.deepcopy(columns_list)\n",
    "        if action_type is not None:\n",
    "            col_list += ['action_type_path']\n",
    "\n",
    "        for col in col_list:\n",
    "            data_dict[col] = df_data[col].split(' ')\n",
    "\n",
    "        path_len = len(data_dict[col])\n",
    "        data_out = []\n",
    "        for i_ in range(path_len):\n",
    "            data_txt = ''\n",
    "            for col_ in columns_list:\n",
    "                if data_dict['action_type_path'][i_] == action_type:\n",
    "                    data_txt += '_' + data_dict[col_][i_]\n",
    "            data_out.append(data_txt)\n",
    "\n",
    "        return len(data_out)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def col_nunique_(df_data, columns_list, action_type):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "        col_list = copy.deepcopy(columns_list)\n",
    "        if action_type is not None:\n",
    "            col_list += ['action_type_path']\n",
    "\n",
    "        for col in col_list:\n",
    "            data_dict[col] = df_data[col].split(' ')\n",
    "\n",
    "        path_len = len(data_dict[col])\n",
    "        data_out = []\n",
    "        for i_ in range(path_len):\n",
    "            data_txt = ''\n",
    "            for col_ in columns_list:\n",
    "                if data_dict['action_type_path'][i_] == action_type:\n",
    "                    data_txt += \"_\" + data_dict[col_][i_]\n",
    "            data_out.append(data_txt)\n",
    "\n",
    "        return len(set(data_out))\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def user_col_cnt(df_data, columns_list, action_type, name):\n",
    "    df_data[name] = df_data.apply(lambda x: col_cnt_(x, columns_list, action_type), axis=1)\n",
    "    return df_data\n",
    "\n",
    "def user_col_nunique(df_data, columns_list, action_type, name):\n",
    "    df_data[name] = df_data.apply(lambda x: col_nunique_(x, columns_list, action_type), axis=1)\n",
    "    return df_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "all_data_test = user_col_cnt(all_data_test, ['seller_path'], '0', 'user_cnt_0')\n",
    "all_data_test = user_col_cnt(all_data_test, ['seller_path'], '1', 'user_cnt_1')\n",
    "all_data_test = user_col_cnt(all_data_test, ['seller_path'], '2', 'user_cnt_2')\n",
    "all_data_test = user_col_cnt(all_data_test, ['seller_path'], '3', 'user_cnt_3')\n",
    "\n",
    "all_data_test = user_col_cnt(all_data_test, ['seller_path', 'item_path'], '0', 'user_cnt_0')\n",
    "all_data_test = user_col_nunique(all_data_test, ['seller_path', 'item_path'], '0', 'seller_nunique_0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['user_id', 'merchant_id', 'label', 'prob', 'age_range', 'gender',\n       'item_path', 'cat_path', 'seller_path', 'brand_path', 'time_stamp_path',\n       'action_type_path', 'user_cnt', 'seller_unique', 'cat_unique',\n       'brand_unique', 'item_unique', 'time_unique', 'action_type_unique',\n       'time_stamp_max', 'time_stamp_min', 'time_stamp_std',\n       'time_stamp_range', 'seller_most_1', 'cat_most_1', 'brand_most_1',\n       'action_type_1', 'seller_most_1_cnt', 'cat_most_1_cnt',\n       'brand_most_1_cnt', 'action_type_1_cnt', 'user_cnt_0', 'user_cnt_1',\n       'user_cnt_2', 'user_cnt_3', 'seller_nunique_0'],\n      dtype='object')"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from scipy import sparse\n",
    "\n",
    "tfidfVec = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1,1), max_features=100)\n",
    "columns_list = ['seller_path']\n",
    "for i, col in enumerate(columns_list):\n",
    "    tfidfVec.fit(all_data_test[col])\n",
    "    data_ = tfidfVec.transform(all_data_test[col])\n",
    "    if i == 0:\n",
    "        data_cat = data_\n",
    "    else:\n",
    "        data_cat = sparse.hstack((data_cat, data_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(data_cat.toarray())\n",
    "df_tfidf.columns = ['tfidf_' + str(i) for i in df_tfidf.columns]\n",
    "all_data_test = pd.concat([all_data_test, df_tfidf], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec(\n",
    "    all_data_test['seller_path'].apply(lambda x: x.split(' ')),\n",
    "    size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4\n",
    ")\n",
    "# model.save(\"product2vec.model\")\n",
    "# model = gensim.models.Word2Vec.load(\"product2vec.model\")\n",
    "\n",
    "def mean_w2v_(x, model, size=100):\n",
    "    try:\n",
    "        i = 0\n",
    "        for word in x.split(' '):\n",
    "            if word in model.wv.vocab:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    vec = np.zeros(size)\n",
    "                vec += model.wv[word]\n",
    "        return vec / i\n",
    "    except:\n",
    "        return np.zeros(size)\n",
    "\n",
    "def get_mean_w2v(df_data, columns, model, size):\n",
    "    data_array = []\n",
    "    for index, row in df_data.iterrows():\n",
    "        w2v = mean_w2v_(row[columns], model, size)\n",
    "        data_array.append(w2v)\n",
    "    return pd.DataFrame(data_array)\n",
    "\n",
    "df_embedding = get_mean_w2v(all_data_test, 'seller_path', model, 100)\n",
    "df_embedding.columns = ['embedding_' + str(i) for i in df_embedding.columns]\n",
    "\n",
    "all_data_test = pd.concat([all_data_test, df_embedding], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-5692f1e1ca44>, line 161)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-1-5692f1e1ca44>\"\u001B[0;36m, line \u001B[0;32m161\u001B[0m\n\u001B[0;31m    def knn_clf(X_train, y_train, X_valid, kf, label_split=None):\u001B[0m\n\u001B[0m                                                                 ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "folds = 5\n",
    "def stacking_clf(clf, train_x, train_y, test_x, clf_name, kf, label_split=None):\n",
    "    train = np.zeros((train_x.shape[0], 1))\n",
    "    test = np.zeros((test_x.shape[0], 1))\n",
    "    test_pre = np.empty((folds, test_x.shape[0], 1))\n",
    "    cv_scores = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train_x, label_split)):\n",
    "        tr_x = train_x[train_index]\n",
    "        tr_y = train_y[train_index]\n",
    "        te_x = train_x[test_index]\n",
    "        te_y = train_y[test_index]\n",
    "\n",
    "        if clf_name in [\"rf\", \"ada\", \"gb\", \"et\", \"lr\", \"knn\", \"gnb\"]:\n",
    "            clf.fit(tr_x, tr_y)\n",
    "            pre = clf.predict_proba(te_x)\n",
    "\n",
    "            train[test_index] = pre[:, 0].reshape(-1, 1)\n",
    "            test_pre[i, :] = clf.predict_proba(test_x)[:, 0].reshape(-1, 1)\n",
    "            cv_scores.append(log_loss(te_y, pre[:, 0].reshape(-1, 1)))\n",
    "        elif clf_name in [\"xgb\"]:\n",
    "            train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-1)\n",
    "            test_matrix = clf.DMatrix(te_x, label=te_y, missing=-1)\n",
    "            z = clf.DMatrix(test_x, label=te_y, missing=-1)\n",
    "            params = {\n",
    "                'booster': 'gbtree',\n",
    "                'objective': 'multi:softprob',\n",
    "                'eval_metric': 'mlogloss',\n",
    "                'gamma': 1,\n",
    "                'min_child_weight': 1.5,\n",
    "                'max_depth': 5,\n",
    "                'lambda': 10,\n",
    "                'subsample': 0.7,\n",
    "                'colsample_bytree': 0.7,\n",
    "                'colsample_bylevel': 0.7,\n",
    "                'eta': 0.03,\n",
    "                'tree_method': 'exact',\n",
    "                'seed': 2017,\n",
    "                'num_class': 2\n",
    "            }\n",
    "\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            watchlist = [(train_matrix, 'train'), (test_matrix, 'eval')]\n",
    "            if test_matrix:\n",
    "                model = clf.train(params,\n",
    "                                  train_matrix,\n",
    "                                  num_boost_round=num_round,\n",
    "                                  evals=watchlist,\n",
    "                                  early_stopping_rounds=early_stopping_rounds)\n",
    "                pre = model.predict(test_matrix,\n",
    "                                    ntree_limit=model.best_ntree_limit)\n",
    "                train[test_index] = pre[:, 0].reshape(-1, 1)\n",
    "                test_pre[i, :] = model.predict(z, ntree_limit=model.best_ntree_limit)[:, 0].reshape(-1,1)\n",
    "                cv_scores.append(log_loss(te_y, pre[:, 0].reshape(-1, 1)))\n",
    "        elif clf_name in [\"lgb\"]:\n",
    "            train_matrix = clf.Dataset(tr_x, label=tr_y)\n",
    "            test_matrix = clf.Dataset(te_x, label=te_y)\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'multiclass',\n",
    "                'metric': 'multi_logloss',\n",
    "                'min_child_weight': 1.5,\n",
    "                'num_leaves': 2**5,\n",
    "                'lambda_l2': 10,\n",
    "                'subsample': 0.7,\n",
    "                'colsample_bytree': 0.7,\n",
    "                'colsample_bylevel': 0.7,\n",
    "                'learning_rate': 0.03,\n",
    "                'tree_method': 'exact',\n",
    "                'seed': 2017,\n",
    "                'num_class': 2,\n",
    "                'silent': True,\n",
    "            }\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            if test_matrix:\n",
    "                model = clf.train(params,\n",
    "                                  train_matrix,\n",
    "                                  num_round,\n",
    "                                  valid_sets = test_matrix,\n",
    "                                  early_stopping_rounds=early_stopping_rounds)\n",
    "                pre = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "                train[test_index] = pre[:, 0].reshape(-1, 1)\n",
    "                test_pre[i, :] = model.predict(test_x, num_iteration=model.best_iteration)[:, 0].reshape(-1, 1)\n",
    "                cv_scores.append(log_loss(te_y, pre[:, 0].reshape(-1, 1)))\n",
    "        else:\n",
    "            raise IOError(\"please add new clf.\")\n",
    "        print(\"%s now score is:\" % clf_name, cv_scores)\n",
    "        test[:] = test_pre.mean(axis=0)\n",
    "        print(\"%s_score_list:\" % clf_name, cv_scores)\n",
    "        print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "\n",
    "        return train.reshape(-1, 1), test.reshape(-1, 1)\n",
    "\n",
    "def rf_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "    randomforest = RandomForestClassifier(n_estimators=1200,\n",
    "                                          max_depth=20,\n",
    "                                          n_jobs=-1,\n",
    "                                          random_state=2017,\n",
    "                                          max_features=\"auto\",\n",
    "                                          verbose=1)\n",
    "    rf_train, rf_test = stacking_clf(randomforest, X_train, y_train, X_valid, \"rf\", kf, label_split=label_split)\n",
    "    return rf_train, rf_test, \"rf\"\n",
    "\n",
    "def ada_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "    adaBoost = AdaBoostClassifier(n_estimators=50, random_state=2017, learning_rate=0.01)\n",
    "    ada_train, ada_test = stacking_clf(adaBoost, X_train, y_train, X_valid, \"ada\", kf, label_split=label_split)\n",
    "    return ada_train, ada_test, \"ada\"\n",
    "\n",
    "def gb_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "    gbdt = GradientBoostingClassifier(learning_rate=0.04, n_estimators=100, subsample=0.8, random_state=2017, max_depth=5, verbose=1)\n",
    "    gbdt_train, gbdt_test = stacking_clf(gbdt, X_train, y_train, X_valid, \"gb\", kf, label_split=label_split)\n",
    "    return gbdt_train, gbdt_test, \"gb\"\n",
    "\n",
    "def et_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "    extraTree = ExtraTreesClassifier(n_estimators=1200, max_depth=35, max_features=\"auto\", n_jobs=-1, random_state=2017, verbose=1)\n",
    "    et_train, et_test = stacking_clf(extraTree, X_train, y_train, X_valid, \"et\", kf, label_split=label_split)\n",
    "    return et_train, et_test, \"et\"\n",
    "\n",
    "def xgb_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "    xgb_train, xgb_test = stacking_clf(xgboost, X_train, y_train, X_valid, \"xgb\", kf, label_split=label_split)\n",
    "    return xgb_train, xgb_test, \"xgb\"\n",
    "\n",
    "def lgb_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "    lgb_train, lgb_test = stacking_clf(lightgbm, X_train, y_train, X_valid, \"lgb\", kf, label_split=label_split)\n",
    "    return lgb_train, lgb_test, \"lgb\"\n",
    "\n",
    "def gnb_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "     gnb = GaussianNB()\n",
    "     gnb_train, gnb_test = stacking_clf(gnb, X_train, y_train, X_valid, \"gnb\", kf, label_split=label_split)\n",
    "     return gnb_train, gnb_test, \"gnb\"\n",
    "\n",
    "def lr_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "     lr = LogisticRegression(n_jobs=-1, random_state=2017, C=0.1, max_iter=200)\n",
    "     lr_train, lr_test = stacking_clf(lr, X_train, y_train, X_valid, \"lr\", kf, label_split=label_split)\n",
    "     return lr_train, lr_test, \"lr\"\n",
    "\n",
    "def knn_clf(X_train, y_train, X_valid, kf, label_split=None):\n",
    "    knn = KNeighborsClassifier(n_neighbors=200, n_jobs=-1)\n",
    "    knn_train, knn_test = stacking_clf(knn, X_train, y_train, X_valid, \"knn\", kf, label_split=label_split)\n",
    "    return knn_train, knn_test, \"knn\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_columns = [c for c in all_data_test.columns if c\n",
    "                   not in ['label', 'prob', 'seller_path', 'cat_path', 'brand_path', 'action_type_path', 'item_path', 'time_stamp_path']]\n",
    "X_train = all_data_test[~all_data_test['label'].isna()][feature_columns].values\n",
    "y_train = all_data_test[~all_data_test['label'].isna()]['label'].values\n",
    "X_valid = all_data_test[all_data_test['label'].isna()][feature_columns].values\n",
    "\n",
    "def get_matrix(data):\n",
    "    where_are_nan = np.isnan(data)\n",
    "    where_are_inf = np.isinf(data)\n",
    "    data[where_are_nan] = 0\n",
    "    data[where_are_inf] = 0\n",
    "    return data\n",
    "X_train = np.float_(get_matrix(np.float_(X_train)))\n",
    "y_train = np.int_(y_train)\n",
    "X_valid = X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "folds = 5\n",
    "seed = 1\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "clf_list = [lgb_clf, xgb_clf]\n",
    "clf_list_col = ['lgb_clf', 'xgb_clf']\n",
    "\n",
    "column_list = []\n",
    "train_data_list = []\n",
    "test_data_list = []\n",
    "for clf in clf_list:\n",
    "    train_data, test_data, clf_name=clf(X_train, y_train, X_valid, kf)\n",
    "    train_data_list.append(train_data)\n",
    "    test_data_list.append(test_data)\n",
    "train_stacking = np.concatenate(train_data_list, axis=1)\n",
    "test_stacking = np.concatenate(test_data_list, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.DataFrame(np.concatenate([X_train, train_stacking], axis=1))\n",
    "test = np.concatenate([X_valid, test_stacking], axis=1)\n",
    "\n",
    "df_train_all = pd.DataFrame(train)\n",
    "df_train_all.columns = feature_columns + clf_list_col\n",
    "df_test_all = pd.DataFrame(test)\n",
    "df_test_all.columns = feature_columns + clf_list_col\n",
    "\n",
    "df_train_all['user_id'] = all_data_test[~all_data_test['label'].isna()]['user_id']\n",
    "df_test_all['user_id'] = all_data_test[all_data_test['label'].isna()]['user_id']\n",
    "df_train_all['label'] = all_data_test[~all_data_test['label'].isna()]['label']\n",
    "\n",
    "df_train_all.to_csv('train_all.csv', header=True, index=False)\n",
    "df_test_all.to_csv('test_all.csv', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-52a413d9",
   "language": "python",
   "display_name": "PyCharm (TwilightStruggle)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}