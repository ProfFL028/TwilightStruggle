{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于自编码器的特征学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 瓶颈层数据完全通过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 670 samples, validate on 330 samples\n",
      "Epoch 1/200\n",
      "670/670 - 1s - loss: 0.2158 - val_loss: 0.1754\n",
      "Epoch 2/200\n",
      "670/670 - 0s - loss: 0.0335 - val_loss: 0.1012\n",
      "Epoch 3/200\n",
      "670/670 - 0s - loss: 0.0214 - val_loss: 0.0544\n",
      "Epoch 4/200\n",
      "670/670 - 0s - loss: 0.0174 - val_loss: 0.0342\n",
      "Epoch 5/200\n",
      "670/670 - 0s - loss: 0.0150 - val_loss: 0.0193\n",
      "Epoch 6/200\n",
      "670/670 - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 7/200\n",
      "670/670 - 0s - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 8/200\n",
      "670/670 - 0s - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 9/200\n",
      "670/670 - 0s - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 10/200\n",
      "670/670 - 0s - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 11/200\n",
      "670/670 - 0s - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 12/200\n",
      "670/670 - 0s - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 13/200\n",
      "670/670 - 0s - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 14/200\n",
      "670/670 - 0s - loss: 0.0085 - val_loss: 0.0047\n",
      "Epoch 15/200\n",
      "670/670 - 0s - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 16/200\n",
      "670/670 - 0s - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 17/200\n",
      "670/670 - 0s - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 18/200\n",
      "670/670 - 0s - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 19/200\n",
      "670/670 - 0s - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 20/200\n",
      "670/670 - 0s - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 21/200\n",
      "670/670 - 0s - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 22/200\n",
      "670/670 - 0s - loss: 0.0072 - val_loss: 0.0040\n",
      "Epoch 23/200\n",
      "670/670 - 0s - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 24/200\n",
      "670/670 - 0s - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 25/200\n",
      "670/670 - 0s - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 26/200\n",
      "670/670 - 0s - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 27/200\n",
      "670/670 - 0s - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 28/200\n",
      "670/670 - 0s - loss: 0.0065 - val_loss: 0.0033\n",
      "Epoch 29/200\n",
      "670/670 - 0s - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 30/200\n",
      "670/670 - 0s - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 31/200\n",
      "670/670 - 0s - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 32/200\n",
      "670/670 - 0s - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 33/200\n",
      "670/670 - 0s - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 34/200\n",
      "670/670 - 0s - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 35/200\n",
      "670/670 - 0s - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 36/200\n",
      "670/670 - 0s - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 37/200\n",
      "670/670 - 0s - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 38/200\n",
      "670/670 - 0s - loss: 0.0058 - val_loss: 0.0029\n",
      "Epoch 39/200\n",
      "670/670 - 0s - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 40/200\n",
      "670/670 - 0s - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 41/200\n",
      "670/670 - 0s - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 42/200\n",
      "670/670 - 0s - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 43/200\n",
      "670/670 - 0s - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 44/200\n",
      "670/670 - 0s - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 45/200\n",
      "670/670 - 0s - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 46/200\n",
      "670/670 - 0s - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 47/200\n",
      "670/670 - 0s - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 48/200\n",
      "670/670 - 0s - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 49/200\n",
      "670/670 - 0s - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 50/200\n",
      "670/670 - 0s - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 51/200\n",
      "670/670 - 0s - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 52/200\n",
      "670/670 - 0s - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 53/200\n",
      "670/670 - 0s - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 54/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 55/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 56/200\n",
      "670/670 - 0s - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 57/200\n",
      "670/670 - 0s - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 58/200\n",
      "670/670 - 0s - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 59/200\n",
      "670/670 - 0s - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 60/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 61/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 62/200\n",
      "670/670 - 0s - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 63/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 64/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 65/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 66/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 67/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 68/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 69/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 70/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 71/200\n",
      "670/670 - 0s - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 72/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 73/200\n",
      "670/670 - 0s - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 74/200\n",
      "670/670 - 0s - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 75/200\n",
      "670/670 - 0s - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 76/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 77/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 78/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 79/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 80/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 81/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 82/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 83/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 84/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 85/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 86/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 87/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 88/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 89/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 90/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 91/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 92/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 93/200\n",
      "670/670 - 0s - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 94/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 95/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 96/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 97/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 98/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 99/200\n",
      "670/670 - 0s - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 100/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 101/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 102/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 103/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 104/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 105/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 106/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 107/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 108/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 109/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 110/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 111/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 112/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 113/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 114/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 115/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 116/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 117/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 118/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 119/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 120/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 121/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 122/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 123/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 124/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 125/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 126/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 127/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 128/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 129/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 130/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 131/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 132/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 133/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 134/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 135/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 136/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 138/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 139/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 9.9616e-04\n",
      "Epoch 140/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 141/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 142/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 143/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 144/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 145/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 146/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 147/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 148/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 149/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 150/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 151/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 152/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 153/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 154/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 155/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 156/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 157/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 158/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 159/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 160/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 161/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 162/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 163/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 164/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 165/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 166/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 167/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 168/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 169/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 170/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 171/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 172/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 173/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 174/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 175/200\n",
      "670/670 - 0s - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 176/200\n",
      "670/670 - 0s - loss: 0.0028 - val_loss: 9.8443e-04\n",
      "Epoch 177/200\n",
      "670/670 - 0s - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 178/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 179/200\n",
      "670/670 - 0s - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 180/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 181/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 182/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 183/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 184/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 185/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 186/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 187/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 188/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 189/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 190/200\n",
      "670/670 - 0s - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 191/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 192/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 193/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 194/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 195/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 196/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 197/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 198/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 9.8655e-04\n",
      "Epoch 199/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 200/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
    "n_inputs = X.shape[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "\n",
    "#编码器\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "#瓶颈层\n",
    "n_bottleneck = n_inputs\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "\n",
    "#解码器\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
    "\n",
    "#绘图\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "#定义编码器模型\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "#保存编码器模型\n",
    "encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               20100     \n",
      "=================================================================\n",
      "Total params: 103,200\n",
      "Trainable params: 102,000\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增加瓶颈层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 670 samples, validate on 330 samples\n",
      "Epoch 1/200\n",
      "670/670 - 1s - loss: 0.2278 - val_loss: 0.1746\n",
      "Epoch 2/200\n",
      "670/670 - 0s - loss: 0.0368 - val_loss: 0.1052\n",
      "Epoch 3/200\n",
      "670/670 - 0s - loss: 0.0233 - val_loss: 0.0539\n",
      "Epoch 4/200\n",
      "670/670 - 0s - loss: 0.0191 - val_loss: 0.0316\n",
      "Epoch 5/200\n",
      "670/670 - 0s - loss: 0.0160 - val_loss: 0.0195\n",
      "Epoch 6/200\n",
      "670/670 - 0s - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 7/200\n",
      "670/670 - 0s - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 8/200\n",
      "670/670 - 0s - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 9/200\n",
      "670/670 - 0s - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 10/200\n",
      "670/670 - 0s - loss: 0.0105 - val_loss: 0.0068\n",
      "Epoch 11/200\n",
      "670/670 - 0s - loss: 0.0104 - val_loss: 0.0069\n",
      "Epoch 12/200\n",
      "670/670 - 0s - loss: 0.0098 - val_loss: 0.0055\n",
      "Epoch 13/200\n",
      "670/670 - 0s - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 14/200\n",
      "670/670 - 0s - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 15/200\n",
      "670/670 - 0s - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 16/200\n",
      "670/670 - 0s - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 17/200\n",
      "670/670 - 0s - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 18/200\n",
      "670/670 - 0s - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 19/200\n",
      "670/670 - 0s - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 20/200\n",
      "670/670 - 0s - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 21/200\n",
      "670/670 - 0s - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 22/200\n",
      "670/670 - 0s - loss: 0.0077 - val_loss: 0.0041\n",
      "Epoch 23/200\n",
      "670/670 - 0s - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 24/200\n",
      "670/670 - 0s - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 25/200\n",
      "670/670 - 0s - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 26/200\n",
      "670/670 - 0s - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 27/200\n",
      "670/670 - 0s - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 28/200\n",
      "670/670 - 0s - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 29/200\n",
      "670/670 - 0s - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 30/200\n",
      "670/670 - 0s - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 31/200\n",
      "670/670 - 0s - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 32/200\n",
      "670/670 - 0s - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 33/200\n",
      "670/670 - 0s - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 34/200\n",
      "670/670 - 0s - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 35/200\n",
      "670/670 - 0s - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 36/200\n",
      "670/670 - 0s - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 37/200\n",
      "670/670 - 0s - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 38/200\n",
      "670/670 - 0s - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 39/200\n",
      "670/670 - 0s - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 40/200\n",
      "670/670 - 0s - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 41/200\n",
      "670/670 - 0s - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 42/200\n",
      "670/670 - 0s - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 43/200\n",
      "670/670 - 0s - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 44/200\n",
      "670/670 - 0s - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 45/200\n",
      "670/670 - 0s - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 46/200\n",
      "670/670 - 0s - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 47/200\n",
      "670/670 - 0s - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 48/200\n",
      "670/670 - 0s - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 49/200\n",
      "670/670 - 0s - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 50/200\n",
      "670/670 - 0s - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 51/200\n",
      "670/670 - 0s - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 52/200\n",
      "670/670 - 0s - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 53/200\n",
      "670/670 - 0s - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 54/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 55/200\n",
      "670/670 - 0s - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 56/200\n",
      "670/670 - 0s - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 57/200\n",
      "670/670 - 0s - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 58/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 59/200\n",
      "670/670 - 0s - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 60/200\n",
      "670/670 - 0s - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 61/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 62/200\n",
      "670/670 - 0s - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 63/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 64/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 65/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 66/200\n",
      "670/670 - 0s - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 67/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 68/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 69/200\n",
      "670/670 - 0s - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 70/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 71/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 72/200\n",
      "670/670 - 0s - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 73/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 74/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 75/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 76/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 77/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 78/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 79/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 80/200\n",
      "670/670 - 0s - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 81/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 82/200\n",
      "670/670 - 0s - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 83/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 84/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 85/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 86/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 87/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 88/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 89/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 90/200\n",
      "670/670 - 0s - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 91/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 92/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 93/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 94/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 95/200\n",
      "670/670 - 0s - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 96/200\n",
      "670/670 - 0s - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 97/200\n",
      "670/670 - 0s - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 98/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 99/200\n",
      "670/670 - 0s - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 100/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 101/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 102/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 103/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 104/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 105/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 106/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 107/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 108/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 109/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 110/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 111/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 112/200\n",
      "670/670 - 0s - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 113/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 114/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 115/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 116/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 117/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 118/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 119/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 120/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 121/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 122/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 123/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 124/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 125/200\n",
      "670/670 - 0s - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 126/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 127/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 128/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 129/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 130/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 131/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 132/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 133/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 134/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 135/200\n",
      "670/670 - 0s - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 136/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200\n",
      "670/670 - 0s - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 138/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 139/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 140/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 141/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 142/200\n",
      "670/670 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 143/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 144/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 145/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 146/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 147/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 148/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 149/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 150/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 151/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 152/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 153/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 154/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 155/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 156/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 157/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 158/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 159/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 160/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 161/200\n",
      "670/670 - 0s - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 162/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 163/200\n",
      "670/670 - 0s - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 164/200\n",
      "670/670 - 0s - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 165/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 166/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 167/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 168/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 169/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 170/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 171/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 172/200\n",
      "670/670 - 0s - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 173/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 174/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 175/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 176/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 177/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 178/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 179/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 180/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 181/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 182/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 183/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 184/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 185/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 186/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 187/200\n",
      "670/670 - 0s - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 188/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 189/200\n",
      "670/670 - 0s - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 190/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 191/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 192/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 193/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 194/200\n",
      "670/670 - 0s - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 195/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 196/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 197/200\n",
      "670/670 - 0s - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 198/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 199/200\n",
      "670/670 - 0s - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 200/200\n",
      "670/670 - 0s - loss: 0.0031 - val_loss: 0.0012\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train autoencoder for classification with with compression in the bottleneck layer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
    "n_inputs = X.shape[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# 瓶颈层数据宽度减半\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器作为预测模型的数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939393939393939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# baseline in performance with logistic regression model\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# fit model on training set\n",
    "model.fit(X_train, y_train)\n",
    "# make prediction on test set\n",
    "yhat = model.predict(X_test)\n",
    "# calculate accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用编码器编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "0.9393939393939394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# evaluate logistic regression on encoded input\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "# load the model from file\n",
    "encoder = load_model('encoder.h5')\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model on the training set\n",
    "model.fit(X_train_encode, y_train)\n",
    "# make predictions on the test set\n",
    "yhat = model.predict(X_test_encode)\n",
    "# calculate classification accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.545px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
