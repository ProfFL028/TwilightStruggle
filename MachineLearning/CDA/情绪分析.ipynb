{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:47:49.337665Z",
     "start_time": "2021-10-20T01:47:45.816486Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import jieba\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:47:52.437161Z",
     "start_time": "2021-10-20T01:47:51.363564Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/zz/8hl03_bd6sj_wrd8__z72r8r0000gn/T/jieba.cache\n",
      "Loading model cost 0.849 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "jieba.load_userdict('{}/NTUSD.txt'.format(cwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:47:57.416168Z",
     "start_time": "2021-10-20T01:47:57.392710Z"
    }
   },
   "outputs": [],
   "source": [
    "NTUSD_POS = list()\n",
    "with open('{}/positive.txt'.format(cwd),'r',encoding='utf-8')as file:\n",
    "    for line in file.readlines():\n",
    "        line = line.strip()\n",
    "        NTUSD_POS.append(line)\n",
    "        \n",
    "NTUSD_NEG = list()\n",
    "with open('{}/negative.txt'.format(cwd),'r',encoding='utf-8')as file:\n",
    "    for line in file.readlines():\n",
    "        line = line.strip()\n",
    "        NTUSD_NEG.append(line)\n",
    "        \n",
    "NTUSD = list()\n",
    "with open('{}/NTUSD.txt'.format(cwd),'r',encoding='utf-8')as file:\n",
    "    for line in file.readlines():\n",
    "        line = line.strip()\n",
    "        NTUSD.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:00.652456Z",
     "start_time": "2021-10-20T01:48:00.645348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "了不起\n",
      "工作过度\n",
      "神智健全\n"
     ]
    }
   ],
   "source": [
    "print(NTUSD_POS[5])\n",
    "print(NTUSD_NEG[102])\n",
    "print(NTUSD[1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:03.720798Z",
     "start_time": "2021-10-20T01:48:03.704491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos:1000\n",
      "neg:1000\n"
     ]
    }
   ],
   "source": [
    "labels,comments = list(),list()\n",
    "pos,neg = 0,0\n",
    "with open('{}/HotelComment_simple.txt'.format(cwd),'r',encoding='utf-8')as file:\n",
    "    for line in file.readlines():\n",
    "        temp = [0,0]\n",
    "        line = line.strip() # line[0] = 0 -> negative; 1 -> positive comment\n",
    "        temp[int(line[0])]=1 # 0 -> 1 0; 1 -> 0 1\n",
    "        if temp[0]==1:\n",
    "            neg+=1\n",
    "        else:\n",
    "            pos+=1\n",
    "        labels.append(temp)\n",
    "        comments.append(line[2:])\n",
    "print('pos:{}\\nneg:{}'.format(pos,neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:05.983466Z",
     "start_time": "2021-10-20T01:48:05.978667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准间太差 房间还不如3星的 而且设施非常陈旧.建议酒店把老的标准间从新改善.\n",
      "[1, 0]\n",
      "距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(comments[0])\n",
    "print(labels[0])\n",
    "print(comments[1000])\n",
    "print(labels[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:08.534939Z",
     "start_time": "2021-10-20T01:48:08.526886Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "chinese = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "number = re.compile(u'[\\u0030-\\u0039]')\n",
    "english = re.compile(u'[\\u0041-\\u005a\\u0061-\\u007a]')\n",
    "\n",
    "def IsChinese(cks):\n",
    "    return chinese.search(cks) and not number.search(cks) and not english.search(cks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:14.240843Z",
     "start_time": "2021-10-20T01:48:12.601318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12249\n"
     ]
    }
   ],
   "source": [
    "PSO = dict()\n",
    "NSO = dict()\n",
    "SO = dict()\n",
    "idf = dict()\n",
    "tf = list()\n",
    "\n",
    "for i in range(pos+neg):\n",
    "    tempTF = dict()\n",
    "    tempIDF = list()\n",
    "    for seg in set(jieba.cut(comments[i])):\n",
    "        if IsChinese(seg):\n",
    "            #PSO NSO#\n",
    "            if labels[i]==[1,0]: # 0 -> 1 0 Negtive Comment\n",
    "                if seg not in NSO:\n",
    "                    NSO[seg]=2\n",
    "                else:\n",
    "                    NSO[seg]+=1\n",
    "            elif labels[i]==[0,1]: # 1 -> 0 1 Positive Comment\n",
    "                if seg not in PSO:\n",
    "                    PSO[seg]=2\n",
    "                else:\n",
    "                    PSO[seg]+=1\n",
    "            #TF IDF#\n",
    "            tempIDF.append(seg)\n",
    "            \n",
    "            if seg not in tempTF:\n",
    "                tempTF[seg]=1\n",
    "            else:\n",
    "                tempTF[seg]+=1\n",
    "                \n",
    "    for key in tempTF:\n",
    "        tempTF[key]=tempTF[key]/len(tempIDF)\n",
    "        \n",
    "    tf.append(tempTF)\n",
    "    \n",
    "    for c in set(tempIDF):\n",
    "        if c not in idf:\n",
    "            idf[c]=1\n",
    "        else:\n",
    "            idf[c]+=1\n",
    "\n",
    "for key in idf:\n",
    "    idf[key]=math.log(len(comments)/idf[key])\n",
    "    \n",
    "for key in PSO:\n",
    "    PSO[key]/=pos\n",
    "    \n",
    "for key in NSO:\n",
    "    NSO[key]/=neg\n",
    "\n",
    "words = list(PSO.keys())\n",
    "words.extend(list(NSO.keys()))\n",
    "words = set(words)\n",
    "\n",
    "print(len(words))\n",
    "\n",
    "for key in words:\n",
    "    if key in PSO and key in NSO:\n",
    "        SO[key]=math.log(PSO[key]/NSO[key])\n",
    "    elif key in PSO and not key in NSO:\n",
    "        SO[key]=math.log(PSO[key]/(1/neg))\n",
    "    elif key not in PSO and key in NSO:\n",
    "        SO[key]=math.log((1/pos)/NSO[key])\n",
    "# sortKey = sorted(SO,key=lambda x:SO[x],reverse=True)\n",
    "# for key in sortKey:\n",
    "#     if key in NTUSD_POS:\n",
    "#         print('{}+:{}'.format(key,SO[key]))\n",
    "#     elif key in NTUSD_NEG:\n",
    "#         print('{}-:{}'.format(key,SO[key]))\n",
    "#     else:\n",
    "#         print('{}:{}'.format(key,SO[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:16.601567Z",
     "start_time": "2021-10-20T01:48:16.551663Z"
    }
   },
   "outputs": [],
   "source": [
    "TFIDF = list()\n",
    "for i in range(len(tf)):\n",
    "    temp = dict()\n",
    "    for key in tf[i]:\n",
    "        temp[key] = tf[i][key]*idf[key]\n",
    "    TFIDF.append(temp)\n",
    "\n",
    "# for i in range(len(TFIDF)):\n",
    "#     sortKey = sorted(TFIDF[i],key=lambda x:TFIDF[i][x],reverse=True)\n",
    "#     for key in sortKey:\n",
    "#         print('{}:{}'.format(key,TFIDF[i][key]))\n",
    "#     print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:18.605641Z",
     "start_time": "2021-10-20T01:48:18.532934Z"
    }
   },
   "outputs": [],
   "source": [
    "TFSO = list()\n",
    "for i in range(len(tf)):\n",
    "    temp = dict()\n",
    "    for key in tf[i]:\n",
    "        temp[key] = tf[i][key]*(abs(SO[key])+1)\n",
    "    TFSO.append(temp)\n",
    "\n",
    "# for i in range(len(TFSO)):\n",
    "#     sortKey = sorted(TFSO[i],key=lambda x:TFSO[i][x],reverse=True)\n",
    "#     for key in sortKey:\n",
    "#         print('{}:{}'.format(key,TFSO[i][key]))\n",
    "#     print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:19.583195Z",
     "start_time": "2021-10-20T01:48:19.509213Z"
    }
   },
   "outputs": [],
   "source": [
    "TFSOIDF = list()\n",
    "for i in range(len(TFIDF)):\n",
    "    temp = dict()\n",
    "    for key in TFIDF[i]:\n",
    "        temp[key] = TFIDF[i][key]*(abs(SO[key])+1)\n",
    "    TFSOIDF.append(temp)\n",
    "\n",
    "# for i in range(len(TFSOIDF)):\n",
    "#     sortKey = sorted(TFSOIDF[i],key=lambda x:TFSOIDF[i][x],reverse=True)\n",
    "#     for key in sortKey:\n",
    "#         print('{}:{}'.format(key,TFSOIDF[i][key]))\n",
    "#     print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:37.461309Z",
     "start_time": "2021-10-20T01:48:20.848429Z"
    }
   },
   "outputs": [],
   "source": [
    "TFSDIDF = list()\n",
    "k = 2\n",
    "for i in range(len(TFIDF)):\n",
    "    temp = dict()\n",
    "    for key in TFIDF[i]:\n",
    "        if key in NTUSD:\n",
    "            temp[key] = TFIDF[i][key]*k\n",
    "        else:\n",
    "            temp[key] = TFIDF[i][key]\n",
    "    TFSDIDF.append(temp)\n",
    "\n",
    "# for i in range(len(TFSDIDF)):\n",
    "#     sortKey = sorted(TFSDIDF[i],key=lambda x:TFSDIDF[i][x],reverse=True)\n",
    "#     for key in sortKey:\n",
    "#         print('{}:{}'.format(key,TFSDIDF[i][key]))\n",
    "#     print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:54.007327Z",
     "start_time": "2021-10-20T01:48:37.464229Z"
    }
   },
   "outputs": [],
   "source": [
    "TFSSIDF = list()\n",
    "k = 2\n",
    "for i in range(len(TFSOIDF)):\n",
    "    temp = dict()\n",
    "    for key in TFSOIDF[i]:\n",
    "        if key in NTUSD:\n",
    "            temp[key] = TFSOIDF[i][key]*k\n",
    "        else:\n",
    "            temp[key] = TFSOIDF[i][key]\n",
    "    TFSSIDF.append(temp)\n",
    "\n",
    "# for i in range(len(TFSSIDF)):\n",
    "#     sortKey = sorted(TFSSIDF[i],key=lambda x:TFSSIDF[i][x],reverse=True)\n",
    "#     for key in sortKey:\n",
    "#         print('{}:{}'.format(key,TFSSIDF[i][key]))\n",
    "#     print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:54.015389Z",
     "start_time": "2021-10-20T01:48:54.010010Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainSVM(swt,lab,words):\n",
    "    x,y = list(),list()\n",
    "    for i in range(len(swt)):\n",
    "        temp = list()\n",
    "        for word in words:\n",
    "            if word in swt[i]:\n",
    "                temp.append(swt[i][word])\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        x.append(temp)\n",
    "        if lab[i]==[0,1]:\n",
    "            y.append(1)\n",
    "        elif lab[i]==[1,0]:\n",
    "            y.append(0)\n",
    "    x,y = np.array(x),np.array(y)\n",
    "    clf = SVC(kernel='linear', C=1.0)\n",
    "    clf.fit(x,y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:48:54.026731Z",
     "start_time": "2021-10-20T01:48:54.017974Z"
    }
   },
   "outputs": [],
   "source": [
    "def testSVM(clf,swt,lab,words):\n",
    "    x,y = list(),list()\n",
    "    for i in range(len(swt)):\n",
    "        temp = list()\n",
    "        for word in words:\n",
    "            if word in swt[i]:\n",
    "                temp.append(swt[i][word])\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        x.append(temp)\n",
    "        if lab[i]==[0,1]:\n",
    "            y.append(1)\n",
    "        elif lab[i]==[1,0]:\n",
    "            y.append(0)\n",
    "    x,y = np.array(x),np.array(y)\n",
    "    predict=clf.predict(x)\n",
    "    correct,wrong = 0,0\n",
    "    for i in range(len(predict)):\n",
    "        if y[i]==predict[i]:\n",
    "            correct+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "    print(round(correct/(correct+wrong),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T01:50:23.749962Z",
     "start_time": "2021-10-20T01:48:54.029516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:1600\n",
      "test:400\n",
      "TFIDF_SVM Accuracy:\n",
      "0.88\n",
      "TFSO_SVM Accuracy:\n",
      "0.81\n",
      "TFSOIDF_SVM Accuracy:\n",
      "0.94\n",
      "TFSDIDF_SVM Accuracy:\n",
      "0.89\n",
      "TFSSIDF_SVM Accuracy:\n",
      "0.93\n"
     ]
    }
   ],
   "source": [
    "index = [i for i in range(len(labels))] # index = [0, 1, 2, ..., 1999]\n",
    "trainIndex = random.sample(index, int(len(labels)*0.8))\n",
    "testIndex = list()\n",
    "for i in index:\n",
    "    if i not in trainIndex:\n",
    "        testIndex.append(i)\n",
    "\n",
    "# trainIndex = index\n",
    "# testIndex = trainIndex\n",
    "print('train:{}'.format(len(trainIndex)))\n",
    "print('test:{}'.format(len(testIndex)))\n",
    "\n",
    "print('TFIDF_SVM Accuracy:')\n",
    "TFIDF_SVM = trainSVM([TFIDF[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFIDF_SVM,[TFIDF[i] for i in testIndex],[labels[i] for i in testIndex],words)\n",
    "\n",
    "print('TFSO_SVM Accuracy:')\n",
    "TFSO_SVM = trainSVM([TFSO[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFSO_SVM,[TFSO[i] for i in testIndex],[labels[i] for i in testIndex],words)\n",
    "\n",
    "print('TFSOIDF_SVM Accuracy:')\n",
    "TFSOIDF_SVM = trainSVM([TFSOIDF[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFSOIDF_SVM,[TFSOIDF[i] for i in testIndex],[labels[i] for i in testIndex],words)\n",
    "\n",
    "print('TFSDIDF_SVM Accuracy:')\n",
    "TFSDIDF_SVM = trainSVM([TFSDIDF[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFSDIDF_SVM,[TFSDIDF[i] for i in testIndex],[labels[i] for i in testIndex],words)\n",
    "\n",
    "print('TFSSIDF_SVM Accuracy:')\n",
    "TFSSIDF_SVM = trainSVM([TFSSIDF[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFSSIDF_SVM,[TFSSIDF[i] for i in testIndex],[labels[i] for i in testIndex],words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:2000\n",
      "test:2000\n",
      "TFIDF_SVM Accuracy:\n",
      "0.96\n",
      "TFSO_SVM Accuracy:\n",
      "0.85\n",
      "TFSOIDF_SVM Accuracy:\n",
      "0.99\n",
      "TFSDIDF_SVM Accuracy:\n",
      "0.97\n",
      "TFSSIDF_SVM Accuracy:\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "index = [i for i in range(len(labels))]\n",
    "trainIndex = index\n",
    "testIndex = trainIndex\n",
    "print('train:{}'.format(len(trainIndex)))\n",
    "print('test:{}'.format(len(testIndex)))\n",
    "\n",
    "print('TFIDF_SVM Accuracy:')\n",
    "TFIDF_SVM = trainSVM([TFIDF[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFIDF_SVM,[TFIDF[i] for i in testIndex],[labels[i] for i in testIndex],words)\n",
    "\n",
    "print('TFSO_SVM Accuracy:')\n",
    "TFSO_SVM = trainSVM([TFSO[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFSO_SVM,[TFSO[i] for i in testIndex],[labels[i] for i in testIndex],words)\n",
    "\n",
    "print('TFSOIDF_SVM Accuracy:')\n",
    "TFSOIDF_SVM = trainSVM([TFSOIDF[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFSOIDF_SVM,[TFSOIDF[i] for i in testIndex],[labels[i] for i in testIndex],words)\n",
    "\n",
    "print('TFSDIDF_SVM Accuracy:')\n",
    "TFSDIDF_SVM = trainSVM([TFSDIDF[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFSDIDF_SVM,[TFSDIDF[i] for i in testIndex],[labels[i] for i in testIndex],words)\n",
    "\n",
    "print('TFSSIDF_SVM Accuracy:')\n",
    "TFSSIDF_SVM = trainSVM([TFSSIDF[i] for i in trainIndex],[labels[i] for i in trainIndex],words)\n",
    "testSVM(TFSSIDF_SVM,[TFSSIDF[i] for i in testIndex],[labels[i] for i in testIndex],words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}