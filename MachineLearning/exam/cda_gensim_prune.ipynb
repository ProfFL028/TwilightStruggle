{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                      id                                       comment_text  \\\n0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n3       0001b41b1c6bb37e  \\nMore\\nI can't make any real suggestions on i...   \n4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n...                  ...                                                ...   \n127652  ffe8b9316245be30  The numbers in parentheses are the additional ...   \n127653  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n127654  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n127655  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n127656  fff46fc426af1f9a  \\nAnd ... I really don't think you understand....   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n0           0             0        0       0       0              0  \n1           0             0        0       0       0              0  \n2           0             0        0       0       0              0  \n3           0             0        0       0       0              0  \n4           0             0        0       0       0              0  \n...       ...           ...      ...     ...     ...            ...  \n127652      0             0        0       0       0              0  \n127653      0             0        0       0       0              0  \n127654      0             0        0       0       0              0  \n127655      0             0        0       0       0              0  \n127656      0             0        0       0       0              0  \n\n[127657 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\\nMore\\nI can't make any real suggestions on i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>127652</th>\n      <td>ffe8b9316245be30</td>\n      <td>The numbers in parentheses are the additional ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>127653</th>\n      <td>ffea4adeee384e90</td>\n      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>127654</th>\n      <td>ffee36eab5c267c9</td>\n      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>127655</th>\n      <td>fff125370e4aaaf3</td>\n      <td>And it looks like it was actually you who put ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>127656</th>\n      <td>fff46fc426af1f9a</td>\n      <td>\\nAnd ... I really don't think you understand....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>127657 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./DATA/training.csv\", encoding='ISO8859-2')\n",
    "data.head(5).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_columns = data.columns[2:]\n",
    "y_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.05419922,  0.01708984, -0.00527954,  0.33203125, -0.25      ,\n       -0.01397705, -0.15039062, -0.265625  ,  0.01647949,  0.3828125 ,\n       -0.03295898, -0.09716797, -0.16308594, -0.04443359,  0.00946045,\n        0.18457031,  0.03637695,  0.16601562,  0.36328125, -0.25585938,\n        0.375     ,  0.171875  ,  0.21386719, -0.19921875,  0.13085938,\n       -0.07275391, -0.02819824,  0.11621094,  0.15332031,  0.09082031,\n        0.06787109, -0.0300293 , -0.16894531, -0.20800781, -0.03710938,\n       -0.22753906,  0.26367188,  0.012146  ,  0.18359375,  0.31054688,\n       -0.10791016, -0.19140625,  0.21582031,  0.13183594, -0.03515625,\n        0.18554688, -0.30859375,  0.04785156, -0.10986328,  0.14355469,\n       -0.43554688, -0.0378418 ,  0.10839844,  0.140625  , -0.10595703,\n        0.26171875, -0.17089844,  0.39453125,  0.12597656, -0.27734375,\n       -0.28125   ,  0.14746094, -0.20996094,  0.02355957,  0.18457031,\n        0.00445557, -0.27929688, -0.03637695, -0.29296875,  0.19628906,\n        0.20703125,  0.2890625 , -0.20507812,  0.06787109, -0.43164062,\n       -0.10986328, -0.2578125 , -0.02331543,  0.11328125,  0.23144531,\n       -0.04418945,  0.10839844, -0.2890625 , -0.09521484, -0.10351562,\n       -0.0324707 ,  0.07763672, -0.13378906,  0.22949219,  0.06298828,\n        0.08349609,  0.02929688, -0.11474609,  0.00534058, -0.12988281,\n        0.02514648,  0.08789062,  0.24511719, -0.11474609, -0.296875  ,\n       -0.59375   , -0.29492188, -0.13378906,  0.27734375, -0.04174805,\n        0.11621094,  0.28320312,  0.00241089,  0.13867188, -0.00683594,\n       -0.30078125,  0.16210938,  0.01171875, -0.13867188,  0.48828125,\n        0.02880859,  0.02416992,  0.04736328,  0.05859375, -0.23828125,\n        0.02758789,  0.05981445, -0.03857422,  0.06933594,  0.14941406,\n       -0.10888672, -0.07324219,  0.08789062,  0.27148438,  0.06591797,\n       -0.37890625, -0.26171875, -0.13183594,  0.09570312, -0.3125    ,\n        0.10205078,  0.03063965,  0.23632812,  0.00582886,  0.27734375,\n        0.20507812, -0.17871094, -0.31445312, -0.01586914,  0.13964844,\n        0.13574219,  0.0390625 , -0.29296875,  0.234375  , -0.33984375,\n       -0.11816406,  0.10644531, -0.18457031, -0.02099609,  0.02563477,\n        0.25390625,  0.07275391,  0.13574219, -0.00138092, -0.2578125 ,\n       -0.2890625 ,  0.10107422,  0.19238281, -0.04882812,  0.27929688,\n       -0.3359375 , -0.07373047,  0.01879883, -0.10986328, -0.04614258,\n        0.15722656,  0.06689453, -0.03417969,  0.16308594,  0.08642578,\n        0.44726562,  0.02026367, -0.01977539,  0.07958984,  0.17773438,\n       -0.04370117, -0.00952148,  0.16503906,  0.17285156,  0.23144531,\n       -0.04272461,  0.02355957,  0.18359375, -0.41601562, -0.01745605,\n        0.16796875,  0.04736328,  0.14257812,  0.08496094,  0.33984375,\n        0.1484375 , -0.34375   , -0.14160156, -0.06835938, -0.14648438,\n       -0.02844238,  0.07421875, -0.07666016,  0.12695312,  0.05859375,\n       -0.07568359, -0.03344727,  0.23632812, -0.16308594,  0.16503906,\n        0.1484375 , -0.2421875 , -0.3515625 , -0.30664062,  0.00491333,\n        0.17675781,  0.46289062,  0.14257812, -0.25      , -0.25976562,\n        0.04370117,  0.34960938,  0.05957031,  0.07617188, -0.02868652,\n       -0.09667969, -0.01281738,  0.05859375, -0.22949219, -0.1953125 ,\n       -0.12207031,  0.20117188, -0.42382812,  0.06005859,  0.50390625,\n        0.20898438,  0.11230469, -0.06054688,  0.33203125,  0.07421875,\n       -0.05786133,  0.11083984, -0.06494141,  0.05639648,  0.01757812,\n        0.08398438,  0.13769531,  0.2578125 ,  0.16796875, -0.16894531,\n        0.01794434,  0.16015625,  0.26171875,  0.31640625, -0.24804688,\n        0.05371094, -0.0859375 ,  0.17089844, -0.39453125, -0.00156403,\n       -0.07324219, -0.04614258, -0.16210938, -0.15722656,  0.21289062,\n       -0.15820312,  0.04394531,  0.28515625,  0.01196289, -0.26953125,\n       -0.04370117,  0.37109375,  0.04663086, -0.19726562,  0.3046875 ,\n       -0.36523438, -0.23632812,  0.08056641, -0.04248047, -0.14648438,\n       -0.06225586, -0.0534668 , -0.05664062,  0.18945312,  0.37109375,\n       -0.22070312,  0.04638672,  0.02612305, -0.11474609,  0.265625  ,\n       -0.02453613,  0.11083984, -0.02514648, -0.12060547,  0.05297852,\n        0.07128906,  0.00063705, -0.36523438, -0.13769531, -0.12890625],\n      dtype=float32)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v = KeyedVectors.load_word2vec_format(\n",
    "    fname=\"//Users/proffl/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "w2v['hello']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def remove_strip(str):\n",
    "    return str.replace(\"\\r\", \"\").replace(\"\\n\", \"\").strip()\n",
    "\n",
    "def get_stop_words(f, encoding='utf-8'):\n",
    "    stop_words = []\n",
    "    with open(f, \"r\", encoding=encoding) as f_stopwords:\n",
    "        for line in f_stopwords:\n",
    "            line = remove_strip(line)\n",
    "            stop_words.append(line.lower())\n",
    "    stop_words = set(stop_words)\n",
    "    print(\"total counts: \", len(stop_words))\n",
    "\n",
    "    return stop_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total counts:  233\n"
     ]
    },
    {
     "data": {
      "text/plain": "233"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = get_stop_words(\"stopwords.txt\")\n",
    "len(stop_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "0         Explanation edits made username Hardcore Metal...\n1         D'aww matches background colour seemingly stuc...\n2         man really trying edit war guy constantly remo...\n3         can't make real suggestions improvement wonder...\n4                      sir hero chance remember page that's\n                                ...                        \n127652    numbers parentheses additional decimal points ...\n127653       ashamed horrible thing put talk page 128611993\n127654    Spitzer Umm theres actual article prostitution...\n127655    looks like actually put speedy first version d...\n127656    really think understand came idea bad right aw...\nName: comment_text_sw, Length: 127657, dtype: object"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text_sw'] = data['comment_text'].apply(\n",
    "    lambda text: \" \".join([w for w in text.replace(\",\", \"\").replace(\"?\", \"\").replace(\".\", \"\").replace(\"!\", \"\").split() if w.lower() not in stop_words]))\n",
    "data['comment_text_sw']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def sentence_to_word(sentence):\n",
    "    word_count = 0\n",
    "    sum_words = np.zeros(300)\n",
    "    for word in sentence.split():\n",
    "        word = word.strip()\n",
    "        if word in w2v.key_to_index:\n",
    "            sum_words = w2v[word] + sum_words\n",
    "            word_count += 1\n",
    "    if word_count > 0:\n",
    "        sum_words = sum_words / word_count\n",
    "    return sum_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6    \\\n0       0.016170  0.054041  0.008723  0.065613 -0.037635 -0.040747 -0.018361   \n1       0.013672  0.071279 -0.039398  0.040609 -0.057129  0.006200  0.075378   \n2       0.081226  0.062378 -0.008158  0.039550 -0.086282  0.070689  0.087277   \n3       0.012383  0.014619  0.036943  0.087166 -0.098782 -0.017439  0.054242   \n4       0.161540  0.058879  0.173024  0.180664 -0.045603 -0.006429  0.086690   \n...          ...       ...       ...       ...       ...       ...       ...   \n127652  0.044643  0.013181  0.071257  0.097162 -0.095079  0.007715  0.034559   \n127653  0.069867  0.088338  0.063371  0.054769 -0.027954  0.031840  0.154887   \n127654  0.043477 -0.024875 -0.086263  0.030362 -0.146620  0.105469 -0.007189   \n127655  0.017097  0.126302  0.057847  0.094198 -0.051073 -0.028998  0.099447   \n127656  0.044189  0.030304  0.031761  0.130107 -0.079898  0.009989  0.099881   \n\n             7         8         9    ...       290       291       292  \\\n0      -0.048341  0.084505  0.004627  ...  0.003094  0.046640 -0.100409   \n1      -0.118815  0.052134  0.049622  ... -0.154256  0.079244  0.010628   \n2      -0.042075  0.069681 -0.035172  ... -0.043018  0.014528 -0.065814   \n3      -0.042736  0.075439  0.024305  ... -0.051308  0.003052 -0.051037   \n4      -0.099447  0.104960  0.090093  ...  0.030334 -0.028900 -0.177775   \n...          ...       ...       ...  ...       ...       ...       ...   \n127652 -0.023131  0.098224  0.092019  ... -0.026332  0.072760 -0.082231   \n127653 -0.057861  0.190267  0.066772  ...  0.019246  0.121582 -0.150798   \n127654 -0.077033  0.037815  0.094177  ... -0.020698 -0.024414 -0.040473   \n127655 -0.005829  0.113953  0.076416  ... -0.041854  0.009006  0.011166   \n127656 -0.053382  0.040068  0.039925  ... -0.125814  0.120365 -0.138492   \n\n             293       294       295       296       297       298       299  \n0       0.064379  0.045702 -0.087487  0.027953 -0.106858 -0.008824 -0.032972  \n1       0.028564  0.075724 -0.153402 -0.078532  0.034414  0.070435  0.023519  \n2       0.019635 -0.080098 -0.048955  0.069958 -0.111234  0.003290  0.034442  \n3       0.020644  0.055660 -0.053549  0.034242 -0.125549 -0.001516 -0.011828  \n4      -0.012655 -0.027486 -0.120829 -0.041748 -0.121948 -0.008708  0.022003  \n...          ...       ...       ...       ...       ...       ...       ...  \n127652 -0.003951 -0.026439  0.048793  0.014121 -0.041830 -0.036802 -0.019561  \n127653  0.083577 -0.159383 -0.147664 -0.044474 -0.126322  0.042653 -0.054036  \n127654  0.080753 -0.048191  0.044569 -0.018324 -0.091404 -0.147135 -0.044403  \n127655  0.046495  0.065240 -0.024821  0.051866 -0.078274 -0.028307 -0.025798  \n127656  0.046231 -0.112892  0.034085  0.076057 -0.032998  0.072188  0.001112  \n\n[127657 rows x 300 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.016170</td>\n      <td>0.054041</td>\n      <td>0.008723</td>\n      <td>0.065613</td>\n      <td>-0.037635</td>\n      <td>-0.040747</td>\n      <td>-0.018361</td>\n      <td>-0.048341</td>\n      <td>0.084505</td>\n      <td>0.004627</td>\n      <td>...</td>\n      <td>0.003094</td>\n      <td>0.046640</td>\n      <td>-0.100409</td>\n      <td>0.064379</td>\n      <td>0.045702</td>\n      <td>-0.087487</td>\n      <td>0.027953</td>\n      <td>-0.106858</td>\n      <td>-0.008824</td>\n      <td>-0.032972</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.013672</td>\n      <td>0.071279</td>\n      <td>-0.039398</td>\n      <td>0.040609</td>\n      <td>-0.057129</td>\n      <td>0.006200</td>\n      <td>0.075378</td>\n      <td>-0.118815</td>\n      <td>0.052134</td>\n      <td>0.049622</td>\n      <td>...</td>\n      <td>-0.154256</td>\n      <td>0.079244</td>\n      <td>0.010628</td>\n      <td>0.028564</td>\n      <td>0.075724</td>\n      <td>-0.153402</td>\n      <td>-0.078532</td>\n      <td>0.034414</td>\n      <td>0.070435</td>\n      <td>0.023519</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.081226</td>\n      <td>0.062378</td>\n      <td>-0.008158</td>\n      <td>0.039550</td>\n      <td>-0.086282</td>\n      <td>0.070689</td>\n      <td>0.087277</td>\n      <td>-0.042075</td>\n      <td>0.069681</td>\n      <td>-0.035172</td>\n      <td>...</td>\n      <td>-0.043018</td>\n      <td>0.014528</td>\n      <td>-0.065814</td>\n      <td>0.019635</td>\n      <td>-0.080098</td>\n      <td>-0.048955</td>\n      <td>0.069958</td>\n      <td>-0.111234</td>\n      <td>0.003290</td>\n      <td>0.034442</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.012383</td>\n      <td>0.014619</td>\n      <td>0.036943</td>\n      <td>0.087166</td>\n      <td>-0.098782</td>\n      <td>-0.017439</td>\n      <td>0.054242</td>\n      <td>-0.042736</td>\n      <td>0.075439</td>\n      <td>0.024305</td>\n      <td>...</td>\n      <td>-0.051308</td>\n      <td>0.003052</td>\n      <td>-0.051037</td>\n      <td>0.020644</td>\n      <td>0.055660</td>\n      <td>-0.053549</td>\n      <td>0.034242</td>\n      <td>-0.125549</td>\n      <td>-0.001516</td>\n      <td>-0.011828</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.161540</td>\n      <td>0.058879</td>\n      <td>0.173024</td>\n      <td>0.180664</td>\n      <td>-0.045603</td>\n      <td>-0.006429</td>\n      <td>0.086690</td>\n      <td>-0.099447</td>\n      <td>0.104960</td>\n      <td>0.090093</td>\n      <td>...</td>\n      <td>0.030334</td>\n      <td>-0.028900</td>\n      <td>-0.177775</td>\n      <td>-0.012655</td>\n      <td>-0.027486</td>\n      <td>-0.120829</td>\n      <td>-0.041748</td>\n      <td>-0.121948</td>\n      <td>-0.008708</td>\n      <td>0.022003</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>127652</th>\n      <td>0.044643</td>\n      <td>0.013181</td>\n      <td>0.071257</td>\n      <td>0.097162</td>\n      <td>-0.095079</td>\n      <td>0.007715</td>\n      <td>0.034559</td>\n      <td>-0.023131</td>\n      <td>0.098224</td>\n      <td>0.092019</td>\n      <td>...</td>\n      <td>-0.026332</td>\n      <td>0.072760</td>\n      <td>-0.082231</td>\n      <td>-0.003951</td>\n      <td>-0.026439</td>\n      <td>0.048793</td>\n      <td>0.014121</td>\n      <td>-0.041830</td>\n      <td>-0.036802</td>\n      <td>-0.019561</td>\n    </tr>\n    <tr>\n      <th>127653</th>\n      <td>0.069867</td>\n      <td>0.088338</td>\n      <td>0.063371</td>\n      <td>0.054769</td>\n      <td>-0.027954</td>\n      <td>0.031840</td>\n      <td>0.154887</td>\n      <td>-0.057861</td>\n      <td>0.190267</td>\n      <td>0.066772</td>\n      <td>...</td>\n      <td>0.019246</td>\n      <td>0.121582</td>\n      <td>-0.150798</td>\n      <td>0.083577</td>\n      <td>-0.159383</td>\n      <td>-0.147664</td>\n      <td>-0.044474</td>\n      <td>-0.126322</td>\n      <td>0.042653</td>\n      <td>-0.054036</td>\n    </tr>\n    <tr>\n      <th>127654</th>\n      <td>0.043477</td>\n      <td>-0.024875</td>\n      <td>-0.086263</td>\n      <td>0.030362</td>\n      <td>-0.146620</td>\n      <td>0.105469</td>\n      <td>-0.007189</td>\n      <td>-0.077033</td>\n      <td>0.037815</td>\n      <td>0.094177</td>\n      <td>...</td>\n      <td>-0.020698</td>\n      <td>-0.024414</td>\n      <td>-0.040473</td>\n      <td>0.080753</td>\n      <td>-0.048191</td>\n      <td>0.044569</td>\n      <td>-0.018324</td>\n      <td>-0.091404</td>\n      <td>-0.147135</td>\n      <td>-0.044403</td>\n    </tr>\n    <tr>\n      <th>127655</th>\n      <td>0.017097</td>\n      <td>0.126302</td>\n      <td>0.057847</td>\n      <td>0.094198</td>\n      <td>-0.051073</td>\n      <td>-0.028998</td>\n      <td>0.099447</td>\n      <td>-0.005829</td>\n      <td>0.113953</td>\n      <td>0.076416</td>\n      <td>...</td>\n      <td>-0.041854</td>\n      <td>0.009006</td>\n      <td>0.011166</td>\n      <td>0.046495</td>\n      <td>0.065240</td>\n      <td>-0.024821</td>\n      <td>0.051866</td>\n      <td>-0.078274</td>\n      <td>-0.028307</td>\n      <td>-0.025798</td>\n    </tr>\n    <tr>\n      <th>127656</th>\n      <td>0.044189</td>\n      <td>0.030304</td>\n      <td>0.031761</td>\n      <td>0.130107</td>\n      <td>-0.079898</td>\n      <td>0.009989</td>\n      <td>0.099881</td>\n      <td>-0.053382</td>\n      <td>0.040068</td>\n      <td>0.039925</td>\n      <td>...</td>\n      <td>-0.125814</td>\n      <td>0.120365</td>\n      <td>-0.138492</td>\n      <td>0.046231</td>\n      <td>-0.112892</td>\n      <td>0.034085</td>\n      <td>0.076057</td>\n      <td>-0.032998</td>\n      <td>0.072188</td>\n      <td>0.001112</td>\n    </tr>\n  </tbody>\n</table>\n<p>127657 rows × 300 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_vec'] = data['comment_text_sw'].map(sentence_to_word)\n",
    "data_word2vec = pd.DataFrame(data['comment_vec'].tolist())\n",
    "data_word2vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存词向量，方便使用\n",
    "data_word2vec.to_csv(\"./DATA/training_vec.csv\", index=None)\n",
    "\n",
    "# data_word2vec = pd.read_csv(\"./DATA/training_vec.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "train set f1 score:  0.9865632510377977\n",
      "training set toxic f1_score: 87.48\n",
      "{'max_depth': 8, 'num_leaves': 200}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "train set f1 score:  0.9973780807551127\n",
      "training set severe_toxic f1_score: 93.99\n",
      "{'max_depth': 8, 'num_leaves': 40}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "train set f1 score:  0.9901652242328874\n",
      "training set obscene f1_score: 89.40\n",
      "{'max_depth': 10, 'num_leaves': 80}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "train set f1 score:  1.0\n",
      "training set threat f1_score: 92.71\n",
      "{'max_depth': 6, 'num_leaves': 40}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "train set f1 score:  0.9604805564337655\n",
      "training set insult f1_score: 88.14\n",
      "{'max_depth': 7, 'num_leaves': 40}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "train set f1 score:  0.9970605526161082\n",
      "training set identity_hate f1_score: 88.07\n",
      "{'max_depth': 7, 'num_leaves': 40}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=5 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-90-b7b63c9cf881>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0mlgb\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0mLGBMClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mboosting_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'dart'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrandom_seed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mgs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlgb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'f1'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m     \u001B[0mgs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0my_train_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    839\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    840\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 841\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    842\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    843\u001B[0m             \u001B[0;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1294\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m         \u001B[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m         \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    805\u001B[0m                                                        **fit_and_score_kwargs)\n\u001B[1;32m    806\u001B[0m                                \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mcand_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 807\u001B[0;31m                                    (split_idx, (train, test)) in product(\n\u001B[0m\u001B[1;32m    808\u001B[0m                                    \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcandidate_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    809\u001B[0m                                    enumerate(cv.split(X, y, groups))))\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001B[0m in \u001B[0;36msplit\u001B[0;34m(self, X, y, groups)\u001B[0m\n\u001B[1;32m    330\u001B[0m                 .format(self.n_splits, n_samples))\n\u001B[1;32m    331\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 332\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    333\u001B[0m             \u001B[0;32myield\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    334\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001B[0m in \u001B[0;36msplit\u001B[0;34m(self, X, y, groups)\u001B[0m\n\u001B[1;32m     78\u001B[0m         \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroups\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindexable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m         \u001B[0mindices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_num_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mtest_index\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iter_test_masks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m             \u001B[0mtrain_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogical_not\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m             \u001B[0mtest_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtest_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001B[0m in \u001B[0;36m_iter_test_masks\u001B[0;34m(self, X, y, groups)\u001B[0m\n\u001B[1;32m    691\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    692\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_iter_test_masks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroups\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 693\u001B[0;31m         \u001B[0mtest_folds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_test_folds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    694\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_splits\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    695\u001B[0m             \u001B[0;32myield\u001B[0m \u001B[0mtest_folds\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001B[0m in \u001B[0;36m_make_test_folds\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    660\u001B[0m         \u001B[0mmin_groups\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_counts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    661\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_splits\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0my_counts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 662\u001B[0;31m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001B[0m\u001B[1;32m    663\u001B[0m                              \u001B[0;34m\" number of members in each class.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    664\u001B[0m                              % (self.n_splits))\n",
      "\u001B[0;31mValueError\u001B[0m: n_splits=5 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "models = []\n",
    "i = 0\n",
    "test_size = 0.25\n",
    "rus = RandomUnderSampler(random_state=random_seed, )\n",
    "X, y= rus.fit_resample(data_word2vec, data[y_columns[i]])\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "lgb =LGBMClassifier(max_depth=8, num_leaves=200, boosting_type='dart', random_state=random_seed)\n",
    "lgb.fit(X_train, y_train)\n",
    "y_train_pred = lgb.predict(X_train)\n",
    "y_valid_pred = lgb.predict(X_valid)\n",
    "print(\"train set f1 score: \", f1_score(y_train, y_train_pred))\n",
    "print(\"training set %s f1_score: %.2f\" % (y_columns[i], f1_score(y_valid, y_valid_pred) * 100))\n",
    "models.append(lgb)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 1\n",
    "rus = RandomUnderSampler(random_state=random_seed, )\n",
    "X, y= rus.fit_resample(data_word2vec, data[y_columns[i]])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "lgb =LGBMClassifier(max_depth=8, num_leaves=40, boosting_type='dart', random_state=random_seed)\n",
    "lgb.fit(X_train, y_train)\n",
    "y_train_pred = lgb.predict(X_train)\n",
    "y_valid_pred = lgb.predict(X_valid)\n",
    "print(\"train set f1 score: \", f1_score(y_train, y_train_pred))\n",
    "print(\"training set %s f1_score: %.2f\" % (y_columns[i], f1_score(y_valid, y_valid_pred) * 100))\n",
    "models.append(lgb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomUnderSampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-562d1b032722>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mrus\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRandomUnderSampler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrandom_seed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mrus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_resample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_word2vec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0my_columns\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_valid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrandom_seed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mlgb\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0mLGBMClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_depth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_leaves\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m80\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mboosting_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'dart'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrandom_seed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'RandomUnderSampler' is not defined"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "rus = RandomUnderSampler(random_state=random_seed, )\n",
    "X, y= rus.fit_resample(data_word2vec, data[y_columns[i]])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "lgb =LGBMClassifier(max_depth=10, num_leaves=80, boosting_type='dart', random_state=random_seed)\n",
    "lgb.fit(X_train, y_train)\n",
    "y_train_pred = lgb.predict(X_train)\n",
    "y_valid_pred = lgb.predict(X_valid)\n",
    "print(\"train set f1 score: \", f1_score(y_train, y_train_pred))\n",
    "print(\"training set %s f1_score: %.2f\" % (y_columns[i], f1_score(y_valid, y_valid_pred) * 100))\n",
    "models.append(lgb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 3\n",
    "rus = RandomUnderSampler(random_state=random_seed, )\n",
    "X, y= rus.fit_resample(data_word2vec, data[y_columns[i]])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "lgb =LGBMClassifier(max_depth=6, num_leaves=40, boosting_type='dart', random_state=random_seed)\n",
    "lgb.fit(X_train, y_train)\n",
    "y_train_pred = lgb.predict(X_train)\n",
    "y_valid_pred = lgb.predict(X_valid)\n",
    "print(\"train set f1 score: \", f1_score(y_train, y_train_pred))\n",
    "print(\"training set %s f1_score: %.2f\" % (y_columns[i], f1_score(y_valid, y_valid_pred) * 100))\n",
    "models.append(lgb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 4\n",
    "rus = RandomUnderSampler(random_state=random_seed, )\n",
    "X, y= rus.fit_resample(data_word2vec, data[y_columns[i]])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "lgb =LGBMClassifier(max_depth=7, num_leaves=40, boosting_type='dart', random_state=random_seed)\n",
    "lgb.fit(X_train, y_train)\n",
    "y_train_pred = lgb.predict(X_train)\n",
    "y_valid_pred = lgb.predict(X_valid)\n",
    "print(\"train set f1 score: \", f1_score(y_train, y_train_pred))\n",
    "print(\"training set %s f1_score: %.2f\" % (y_columns[i], f1_score(y_valid, y_valid_pred) * 100))\n",
    "models.append(lgb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 5\n",
    "rus = RandomUnderSampler(random_state=random_seed, )\n",
    "X, y= rus.fit_resample(data_word2vec, data[y_columns[i]])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "lgb =LGBMClassifier(max_depth=7, num_leaves=40, boosting_type='dart', random_state=random_seed)\n",
    "lgb.fit(X_train, y_train)\n",
    "y_train_pred = lgb.predict(X_train)\n",
    "y_valid_pred = lgb.predict(X_valid)\n",
    "print(\"train set f1 score: \", f1_score(y_train, y_train_pred))\n",
    "print(\"training set %s f1_score: %.2f\" % (y_columns[i], f1_score(y_valid, y_valid_pred) * 100))\n",
    "models.append(lgb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./DATA/test.csv\", encoding='ISO8859-2')\n",
    "test['comment_text_sw'] = test['comment_text'].apply(\n",
    "    lambda text: \" \".join([w for w in text.replace(\",\", \"\").replace(\"?\", \"\").replace(\".\", \"\").replace(\"!\", \"\").split() if w.lower() not in stop_words]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "test['comment_vec'] = test['comment_text_sw'].map(sentence_to_word)\n",
    "test_word2vec = pd.DataFrame(test['comment_vec'].tolist())\n",
    "result = test['id']\n",
    "for (idx, column) in enumerate(y_columns[:-2]):\n",
    "    y_test = models[idx].predict(test_word2vec)\n",
    "    result = pd.concat([result, pd.DataFrame(y_test, columns=[column], index=test.index)], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# for y in ['toxic','severe_toxic','obscene','threat','insult','identity_hate']:\n",
    "#     result[y] = result[y].map({0:'L', 1:'H'})\n",
    "result.to_csv(\"方笠_results.csv\", index=None)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}